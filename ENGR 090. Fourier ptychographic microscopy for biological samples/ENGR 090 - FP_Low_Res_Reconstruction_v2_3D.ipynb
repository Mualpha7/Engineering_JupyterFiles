{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "Initial system NA is  0.3\n",
      "Loading in images...\n",
      "Finish loading images\n",
      "number of brightfield LEDs:  69\n",
      "synthetic NA is  0.5555729354176789\n",
      "achieved resolution is:  0.4661854159711437\n",
      "synthetic_NA:  0.5555729354176789\n",
      "WARNING:tensorflow:From /mnt/saturn/jupyterhub_data/fveronf1/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "<tensorflow.python.ops.variable_scope.VariableScope object at 0x7fd4a033e080>\n",
      "Killed\n"
     ]
    }
   ],
   "source": [
    "!python3 FP_Low_Res_Reconstruction_v2_3D.py --input Flatworm_SampleNumber0002_RegionNumber0001 \\\n",
    "    --output patch_4 -g 1 --np 128 --nstart_x 448 --nstart_y 448 --background 105.0721893787384 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--input INPUT] [--output OUTPUT]\n",
      "                             [-g NUM_GPUS] [--np NP] [--nstart_x NSTART_X]\n",
      "                             [--nstart_y NSTART_Y]\n",
      "                             [--background BACKGROUND_THRESHOLD]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /mnt/saturn/jupyterhub_data/fveronf1/.local/share/jupyter/runtime/kernel-358f6446-3fa6-4790-98ae-72c6ae28ba58.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FP_Low_Res_Reconstruction combines FPSystemSetup.py and FP_Optimizer_lowResInput.py into one file \n",
    "Purpose: Allow for tuning of parameters using Tensorflow \n",
    "\"\"\"\n",
    "\n",
    "# Import necessary functions \n",
    "\n",
    "import TensorFlowFunctions as tff \n",
    "from layer_defs import variable_on_cpu\n",
    "from FP_Reconstruction_Functions_3D import read_images, derived_params, \\\n",
    "                                        create_low_res_stack_singleLEDs_multipupil_3D, \\\n",
    "                                        CalculateParameters, NAfilter, scalar_prop\n",
    "from ShiftAddFunctions import get_derived_params_SA, shift_add\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from scipy import signal\n",
    "import os, argparse, time, sys\n",
    "\n",
    "version = 57\n",
    "print(version)\n",
    "\n",
    "### Accept command line inputs \n",
    "##############################################################################\n",
    "\n",
    "# Function to parse input from command line \n",
    "# Inputs \n",
    "# --data: Path for input unprocessed dataset\n",
    "# --folder: Path for output reconstruction images \n",
    "# --size-leds: Diameter of illumination \n",
    "def parseCommandLineInput():\n",
    "    parser = argparse.ArgumentParser(description='Get command line args')\n",
    "    \n",
    "    parser.add_argument('--input', action='store', help='path for input unprocessed dataset (images)')\n",
    "    \n",
    "    parser.add_argument('--output', action='store', help='path for output dataset')\n",
    "    \n",
    "    parser.add_argument('-g', type=int, action='store', dest='num_gpus', \\\n",
    "                        help='number of GPUs')\n",
    "    \n",
    "    parser.add_argument('--np', type=int, action='store', dest='np', \\\n",
    "                        help='Np = side length of low resolution image ')\n",
    "    \n",
    "    parser.add_argument('--nstart_x', type=int, action='store', dest='nstart_x', \\\n",
    "                        help='Starting coordinate for defining region of interest, row coordinate')    \n",
    "\n",
    "    parser.add_argument('--nstart_y', type=int, action='store', dest='nstart_y', \\\n",
    "                        help='Starting coordinate for defining region of interest, column coordinate')    \n",
    "\n",
    "    parser.add_argument('--background', type=float, action='store', dest='background_threshold', \\\n",
    "                            help='background_threshold')\n",
    "        \n",
    "    return parser \n",
    "\n",
    "# Parse input from command line \n",
    "parser = parseCommandLineInput()\n",
    "# Store input arguments \n",
    "args = parser.parse_args()\n",
    "\n",
    "# Define input folder \n",
    "input_folder_name = args.input\n",
    "\n",
    "# Define output folder\n",
    "output_folder = args.output \n",
    "        \n",
    "# Side length of low resolution image \n",
    "Np = args.np\n",
    "\n",
    " # Starting coordinate for defining region of interest\n",
    "nstart = [args.nstart_x, args.nstart_y]\n",
    "\n",
    "background_threshold = args.background_threshold\n",
    "\n",
    "# Number of GPUs to use for training   \n",
    "num_GPUs = args.num_gpus \n",
    "\n",
    "\n",
    "### Define processing Region of Interest \n",
    "##############################################################################\n",
    "upsample_factor = 2 # XXX add a check that makes sure this factor is large enough\n",
    "                    # upsampling factor must support NA = 2\n",
    "                    # 6\n",
    "N_obj = Np*upsample_factor\n",
    "\n",
    "\n",
    "# Define whether to perform background removal \n",
    "#############################################################################\n",
    "background_removal = True\n",
    "\n",
    "\n",
    "### Define parameters describing the optical system \n",
    "##############################################################################\n",
    "# Wavelength of illumination \n",
    "# Adjust accordingly \n",
    "wavelength = 0.518 \n",
    "# R: 624.4nm +- 50nm \n",
    "# G: 518.0nm +- 50nm \n",
    "# B: 476.4nm +- 50nm \n",
    "\n",
    "# Numerical Aperture of Objective\n",
    "# Adjust accordingly \n",
    "NA = 0.3 #0.5 for 20x and 0.3 for 10x \n",
    "print(\"Initial system NA is \", NA)\n",
    "\n",
    "# Magnification of the system \n",
    "# Adjust accodingly \n",
    "mag = 9.24 #9.24 for 10x #18.48 for 20x\n",
    "\n",
    "# Diameter of pixel on sensor plane \n",
    "# Adjust accordingly\n",
    "dpix_c = 6.5 # 6.5um pixel size on the sensor plane \n",
    "\n",
    "# LED array geometries\n",
    "# Adjust accordingly \n",
    "ds_led = 4e3 # 4mm, spacing between neighboring LEDs\n",
    "z_led = 69.5e3 # Z distance between LED and imaged object \n",
    "lit_cenv = 15 # center LED in the row direction\n",
    "lit_cenh = 16 # center LED in the column direction\n",
    "dia_led = 9.0 # diameter of used LEDs \n",
    "\n",
    "\n",
    "N_obj_center = [2048*upsample_factor//2, 2048*upsample_factor//2] #coords of object center, corresponds to center LED\n",
    "\n",
    "\n",
    "# Define patch parameters \n",
    "num_patches = 1 \n",
    "N_patch = N_obj//num_patches #patches that make up the high res object\n",
    "\n",
    "\n",
    "### Define training parameters \n",
    "# Adjust accordingly \n",
    "##############################################################################\n",
    "training_rate = 2e-1 # Rate of training \n",
    "sqrt_reg = 1e-8 # Square-root regularization \n",
    "num_iter = 10 # Number of iterations to train for \n",
    "restore_model = False # Whether to restore the model for every restore_iter\n",
    "restore_iter = 20000 # Graph restoration point \n",
    "save_checkpoint_interval = 100000 # Checkpoint saving interval defined\n",
    "save_vars_interval = 1000 #100000 # Variable saving interval defined \n",
    "change_pupil = True\n",
    "change_Ns_mat = False ### This option doesn't work for 3D, don't change from False\n",
    "change_scale_mat = False\n",
    "num_stacks = 1\n",
    "\n",
    "# Get collected low-resolution images\n",
    "\n",
    "Imea = read_images(input_folder_name, Np, nstart, background_removal, background_threshold, num_stacks)\n",
    "\n",
    "# Get derived parameters\n",
    "\n",
    "numLEDs,dx_obj, hhled, vvled, du, LitCoord, um_m, pupil = derived_params(NA, wavelength, dpix_c, mag, Np, \\\n",
    "                                                                         lit_cenh, lit_cenv, dia_led, N_obj)\n",
    "\n",
    "# Obtain the values for Ns_mat and scale_mat \n",
    "\n",
    "Ns_mat = np.zeros([num_patches**2,numLEDs,2])\n",
    "scale_mat = np.zeros([num_patches**2,numLEDs])\n",
    "count = 0\n",
    "for i,startX in enumerate(np.arange(0,N_obj,N_patch)):\n",
    "    for j,startY in enumerate(np.arange(0,N_obj,N_patch)):\n",
    "        N_obj_patch_coord = np.array([startX,startY]) + np.array(nstart)*upsample_factor # upper left corner of object patch which will be downconverted to low-resolution\n",
    "        N_patch_center = N_obj_patch_coord + N_obj/num_patches/2 \n",
    "        \n",
    "        # pass the full object to HiToLoPatch\n",
    "        Ns, scale, synthetic_NA = CalculateParameters(N_patch_center, N_obj_center, dx_obj, hhled, ds_led, \\\n",
    "                        vvled, z_led, wavelength, du, LitCoord, numLEDs, NA, um_m)\n",
    "        \n",
    "        Ns_mat[count,:,:]=Ns\n",
    "        scale_mat[count,:]=scale\n",
    "        count += 1\n",
    "        \n",
    "        print('synthetic_NA: ', synthetic_NA)\n",
    "\n",
    "\n",
    "# Determine synthetic NAfilter\n",
    "NAfilter_synthetic = NAfilter(int(N_obj),dx_obj*N_obj*1e-6,wavelength*1e-6,synthetic_NA)\n",
    "\n",
    "# Determine NAfilter for NA=2\n",
    "NAfilter_2 = NAfilter(int(N_obj),dx_obj*N_obj*1e-6,wavelength*1e-6,2.0)\n",
    "\n",
    "\n",
    "# Determine NAfilter for NA=1 + illumination NA\n",
    "NAfilter_3 = NAfilter(int(N_obj),dx_obj*N_obj*1e-6,wavelength*1e-6,1+synthetic_NA-NA)\n",
    "\n",
    "# Display Pre-processing data and synthetic NA \n",
    "##############################################################################\n",
    "\n",
    "\n",
    "## print synthetic NA\n",
    "#plt.figure()\n",
    "#plt.imshow(NAfilter_synthetic)\n",
    "#plt.colorbar()\n",
    "#\n",
    "## print NA = 2, if it doesn't fit, increase the upsample factor\n",
    "#plt.figure()\n",
    "#plt.imshow(NAfilter_2)\n",
    "#plt.colorbar()\n",
    "#\n",
    "## print NAfilter_3\n",
    "#plt.figure()\n",
    "#plt.imshow(NAfilter_3)\n",
    "#plt.colorbar()\n",
    "#\n",
    "#\n",
    "## Show low-resolution images\n",
    "#plt.figure()\n",
    "#plt.imshow(Imea[5])\n",
    "#plt.figure()\n",
    "#plt.imshow(Imea[10])\n",
    "\n",
    "\n",
    "\n",
    "### Pre-process variables for reconstruction\n",
    "# Slight reformatting of variables  \n",
    "##############################################################################\n",
    "# cen0: Coordinates for object patch center\n",
    "cen0 = np.array([N_obj//2,N_obj//2], dtype=np.float32) #N_obj_center\n",
    "\n",
    "\n",
    "# Np: Lower resolution side length \n",
    "Np = int(Np)\n",
    "\n",
    "### Define a training folder\n",
    "##############################################################################\n",
    "### Make output folder\n",
    "training_folder = input_folder_name + '/' + output_folder\n",
    "try: \n",
    "    os.makedirs(training_folder)\n",
    "except OSError:\n",
    "    if not os.path.isdir(training_folder):\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save Inputs\n",
    "#############################################################################\n",
    "np.savez(training_folder + '/input_vars.npz',                        \n",
    "         Np = Np,\n",
    "         nstart = nstart,\n",
    "         background_threshold = background_threshold,\n",
    "         num_GPUs = num_GPUs)\n",
    "\n",
    "\n",
    "# Make GPU_devices_vec \n",
    "#############################################################################\n",
    "if num_GPUs: \n",
    "    GPU_devices_vec=[];\n",
    "    for num in list(range(num_GPUs)) :\n",
    "        GPU_devices_vec.append('/device:GPU:'+str(num))\n",
    "else:\n",
    "    GPU_devices_vec=['/cpu:0']\n",
    "    num_GPUs = 1 \n",
    "\n",
    "\n",
    "\n",
    "indices0=[]\n",
    "for g in list(range(num_GPUs)):\n",
    "    if g == (num_GPUs-1):\n",
    "        indices0.append(list(range(g*(numLEDs//num_GPUs),numLEDs)))\n",
    "    else:    \n",
    "        indices0.append(list(range(g*(numLEDs//num_GPUs),(g+1)*(numLEDs//num_GPUs))))\n",
    " \n",
    "# Load z variables\n",
    "\n",
    "dz = np.load(input_folder_name + '/dz.npy')\n",
    "z_vec = np.load(input_folder_name + '/z_vec.npy')\n",
    "Nz = len(z_vec)\n",
    "\n",
    "# Initial condition\n",
    "\n",
    "tot_mat = np.load(input_folder_name + '/tot_mat.npy')\n",
    "tot_mat = tot_mat[:,nstart[0]:nstart[0]+Np,nstart[1]:nstart[1]+Np]\n",
    "\n",
    "bits = 2**16 - 1\n",
    "       \n",
    "initial_guess = np.sqrt(tot_mat/float(numLEDs))\n",
    "initial_guess = initial_guess/float(upsample_factor**2) \n",
    "initial_guess = initial_guess**(1./float(Nz))    \n",
    "#initial_guess = initial_guess/100.0   \n",
    "initial_guess = signal.resample(initial_guess, N_obj, axis=1)\n",
    "initial_guess = signal.resample(initial_guess, N_obj, axis=2)                      \n",
    "initial_guess = initial_guess.astype(np.float32)\n",
    "\n",
    "# Create H_prop\n",
    "H_prop_dz_np = scalar_prop(N_obj,N_obj,dx_obj,dx_obj,dz,wavelength)\n",
    "H_prop_focal_plane_np = scalar_prop(N_obj,N_obj,dx_obj,dx_obj,-z_vec[-1],wavelength)\n",
    "      \n",
    "np.save(training_folder + '/low_res_stack_actual.npy', Imea)\n",
    "np.save(training_folder + '/LitCoord.npy', LitCoord)\n",
    "\n",
    "#sys.exit()\n",
    "\n",
    "# Start Timer\n",
    "trainingStart=time.time()\n",
    "\n",
    "# Tensorflow Graph\n",
    "with tf.Graph().as_default():\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "        \n",
    "        H_prop_dz = tf.constant(H_prop_dz_np, dtype=tf.complex64)\n",
    "        \n",
    "        H_prop_focal_plane = tf.constant(H_prop_focal_plane_np, dtype=tf.complex64)\n",
    "        \n",
    "        # actual low-resolution images\n",
    "        low_res_stack_actual = tf.constant(Imea[0:numLEDs,:,:], dtype=tf.float32)\n",
    "    \n",
    "        \n",
    "        global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "    \n",
    "        # Decay the learning rate exponentially based on the number of steps.\n",
    "        training_rate_decay = tf.train.exponential_decay(training_rate,\n",
    "                                        global_step,\n",
    "                                        1000, # decay_steps \n",
    "                                        0.999, # decay_rate\n",
    "                                        staircase=True)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=training_rate_decay, epsilon=1e-3) #1e-2 #1e-3 #1e-4\n",
    "    \n",
    "    \n",
    "    ##############\n",
    "        tower_grads = []\n",
    "        sum_tower_loss = []\n",
    "        low_res_stack_predicted_dict = {}\n",
    "\n",
    "\n",
    "        with tf.variable_scope(tf.get_variable_scope()):\n",
    "            print(tf.get_variable_scope())\n",
    "            for g,gpu in enumerate(GPU_devices_vec):\n",
    "                with tf.device(gpu):\n",
    "                    \n",
    "                    if change_pupil:\n",
    "                        \n",
    "                        pupil0 = tf.expand_dims(tf.constant(pupil, dtype = tf.complex64),axis=0)\n",
    "                        \n",
    "                        \n",
    "                        P_angle = variable_on_cpu('pupil_angle', \\\n",
    "                                                  np.zeros([num_patches**2,int(Np),int(Np)]).astype(np.float32), \\\n",
    "                                                  tf.float32)\n",
    "                        \n",
    "                        P = tf.exp(tf.cast(P_angle, tf.complex64)*1j)*pupil0\n",
    "                    else:\n",
    "                        \n",
    "                        P = tf.constant(pupil, dtype = tf.complex64)\n",
    "    \n",
    "                    if change_Ns_mat:\n",
    "                        Ns_mat_tf = variable_on_cpu('Ns_mat_tf', \\\n",
    "                                                  Ns_mat.astype(np.float32), \\\n",
    "                                                  tf.float32)\n",
    "                    else:\n",
    "                        Ns_mat_tf = tf.constant(Ns_mat, dtype=tf.float32)\n",
    "                    \n",
    "                    \n",
    "                    if change_scale_mat:\n",
    "                        scale_mat_tf = variable_on_cpu('scale_mat_tf', \\\n",
    "                                                  scale_mat.astype(np.float32), \\\n",
    "                                                  tf.float32)\n",
    "                    else:\n",
    "                        scale_mat_tf = tf.constant(scale_mat, dtype=tf.float32)\n",
    "                \n",
    "\n",
    "\n",
    "                    high_res_guess_real = variable_on_cpu('high_res_guess_real', \\\n",
    "                                                          initial_guess,\n",
    "                                                          tf.float32)\n",
    "                    high_res_guess_img = variable_on_cpu('high_res_guess_img', \\\n",
    "                                                         np.zeros([int(Nz),int(N_obj),int(N_obj)], dtype=np.float32), \n",
    "                                                         tf.float32)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    high_res_guess = tf.cast(high_res_guess_real, tf.complex64) + 1j*tf.cast(high_res_guess_img, tf.complex64)\n",
    "                    \n",
    "                \n",
    "                    low_res_stack_predicted = create_low_res_stack_singleLEDs_multipupil_3D(high_res_guess, H_prop_dz, H_prop_focal_plane, \\\n",
    "                                                                                            Nz, numLEDs, N_obj, \\\n",
    "                                                                                            N_patch, num_patches, Ns_mat_tf, scale_mat_tf, \\\n",
    "                                                                                            cen0, P, Np, indices0[g], change_pupil, change_Ns_mat)\n",
    "                    \n",
    "                    # compare the stack of low resolution images to the actual low resolution images\n",
    "                   \n",
    "                    low_res_stack_actual0 = tf.gather(low_res_stack_actual, indices0[g])\n",
    "\n",
    "#                    loss_MSE = tf.reduce_sum(tf.square(tf.sqrt(low_res_stack_actual0 + sqrt_reg) - tf.sqrt(low_res_stack_predicted + sqrt_reg)))\n",
    "                    loss_MSE = tf.reduce_sum(tf.square(tf.sqrt(low_res_stack_actual0) - tf.sqrt(low_res_stack_predicted)))\n",
    "#                    loss_MSE = tf.reduce_sum(tf.square(low_res_stack_actual0 - low_res_stack_predicted))\n",
    "\n",
    "#                    loss_grad_diff = tff.grad_diff_loss(low_res_stack_predicted, low_res_stack_actual0)\n",
    "#                    \n",
    "#                    if change_pupil:\n",
    "#                        alpha = 1e-1\n",
    "#                        pupil_change_penalty = alpha*tf.reduce_sum(tf.square(tf.abs(pupil0-P)))\n",
    "#                        loss_i = loss_MSE + loss_grad_diff*0 + pupil_change_penalty*0\n",
    "#                    else:\n",
    "#                        loss_i = loss_MSE + loss_grad_diff*0\n",
    "                \n",
    "                    loss_i = loss_MSE\n",
    "                    \n",
    "                    loss_i = loss_i*len(indices0[g])*num_GPUs/float(numLEDs)\n",
    "                    \n",
    "                    grads = optimizer.compute_gradients(loss_i)\n",
    "                    \n",
    "                    tower_grads.append(grads)\n",
    "                    sum_tower_loss.append(loss_i)\n",
    "                    low_res_stack_predicted_dict[g] = low_res_stack_predicted\n",
    "                    \n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "\n",
    "        loss=tf.add_n(sum_tower_loss)\n",
    "        \n",
    "        # We must calculate the mean of each gradient. Note that this is the\n",
    "        # synchronization point across all towers.\n",
    "        grads = tff.average_gradients(tower_grads, take_average=False)\n",
    "\n",
    "    \n",
    "        # Apply the gradients to adjust the shared variables.\n",
    "        apply_gradient_op = optimizer.apply_gradients(grads, global_step=global_step)\n",
    "            \n",
    "        init_op = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()  \n",
    "  \n",
    "        config = tf.ConfigProto(\n",
    "                device_count = {'GPU': num_GPUs},\n",
    "                allow_soft_placement=True,\n",
    "                log_device_placement=False\n",
    "                )    \n",
    "  \n",
    "        \n",
    "    with tf.Session(config=config) as sess: \n",
    "        if restore_model:\n",
    "            \n",
    "            saver.restore(sess, training_folder + '/model.ckpt-' + str(restore_iter))\n",
    "            print(\"Model restored.\")\n",
    "            \n",
    "            iter_vec = np.load(training_folder + '/iter_vec.npy').tolist()\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            restore_iter = -1\n",
    "            \n",
    "            sess.run(init_op)\n",
    "            \n",
    "            iter_vec=[]\n",
    "\n",
    "\n",
    "        for i in list(range(restore_iter + 1, restore_iter + 1 + num_iter)):\n",
    "                    \n",
    "            if ( ((i%save_vars_interval)==0) or (i==(restore_iter + 1 + num_iter - 1))):\n",
    "\n",
    "                folder_name = training_folder\n",
    "                    \n",
    "\n",
    "                [ _ ,\n",
    "                 loss0,\n",
    "                 high_res_guess0,\n",
    "                 P0,\n",
    "                 Ns_mat0,\n",
    "                 scale_mat0,\n",
    "                 low_res_stack_predicted_dict0]= sess.run([apply_gradient_op,\n",
    "                                                           loss,\n",
    "                                                           high_res_guess,\n",
    "                                                           P,\n",
    "                                                           Ns_mat_tf,\n",
    "                                                           scale_mat_tf,\n",
    "                                                           low_res_stack_predicted_dict])\n",
    "                  \n",
    "                                     \n",
    "                np.save(folder_name + '/loss' + str(i) + '.npy', loss0)\n",
    "                np.save(folder_name + '/high_res_guess' + str(i) + '.npy', high_res_guess0)\n",
    "                np.save(folder_name + '/P' + str(i) + '.npy', P0)\n",
    "                np.save(folder_name + '/Ns_mat' + str(i) + '.npy', Ns_mat0)\n",
    "                np.save(folder_name + '/scale_mat' + str(i) + '.npy', scale_mat0)\n",
    "                np.save(folder_name + '/low_res_stack_predicted_dict' + str(i) + '.npy', low_res_stack_predicted_dict0)\n",
    "\n",
    "                \n",
    "                iter_vec.append(i) \n",
    "                np.save(folder_name + '/iter_vec.npy', iter_vec)\n",
    "                \n",
    "                                      \n",
    "                print('iteration: ',i) \n",
    "                print('loss training:   ', loss0)            \n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "                sess.run(apply_gradient_op) \n",
    "\n",
    " \n",
    "            if ( ((i%save_checkpoint_interval)==0) and (i>0) ): # or (i==(restore_iter + 1 + num_iter - 1))):\n",
    "                save_path = saver.save(sess, training_folder + '/model.ckpt',global_step=i)\n",
    "                print(\"Model saved in file: %s\" % save_path)  \n",
    "          \n",
    "### End Timer    \n",
    "trainingEnd=time.time()\n",
    "trainingTotalTime=trainingEnd-trainingStart\n",
    "print('Training took', trainingTotalTime, 'seconds.')\n",
    "np.save(folder_name + '/training_time.npy', trainingTotalTime)\n",
    "\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
