{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import misc\n",
    "import glob\n",
    "\n",
    "from autoencode import AutoEncoder\n",
    "from layer_defs import variable_on_cpu, getConvInitializer\n",
    "\n",
    "\n",
    "def fftshift(mat2D, dim0, dim1): #fftshift == ifftshift when dimensions are all even\n",
    "                                 #fftshift only works with even dimensions\n",
    "\n",
    "    if (dim0==1) and (dim1==1):\n",
    "        return mat2D    \n",
    "    \n",
    "    if (dim0%2) or (dim1%2):\n",
    "        raise ValueError('Dimensions must be even to use fftshift.')\n",
    "\n",
    "    dim0=tf.cast(dim0,tf.int32)\n",
    "    dim1=tf.cast(dim1,tf.int32)\n",
    "\n",
    "    piece1=tf.slice(mat2D,[0,0],[dim0//2,dim1//2])\n",
    "    piece2=tf.slice(mat2D,[0,dim1//2],[dim0//2,dim1//2])\n",
    "    piece3=tf.slice(mat2D,[dim0//2,0],[dim0//2,dim1//2])\n",
    "    piece4=tf.slice(mat2D,[dim0//2,dim1//2],[dim0//2,dim1//2])\n",
    "\n",
    "    top=tf.concat([piece4,piece3],axis=1)\n",
    "    bottom=tf.concat([piece2,piece1],axis=1)\n",
    "\n",
    "    final=tf.concat([top,bottom],axis=0)\n",
    "    return final\n",
    "\n",
    "\n",
    "def propTF_withNA_PSFcustom(u1,H_fresnel,H_NA,PSF,m,incoherent=1):\n",
    "    #u1 is the source plane field\n",
    "    #L is the side length of the observation and source fields (assume square fields)\n",
    "\n",
    "    #NA is the numerical aperture\n",
    "    #m is u1.shape[0], is a tf.int32\n",
    "    #dx is L/m\n",
    "\n",
    "    PSF_phase=2*math.pi*PSF\n",
    "    PSF_phase=tf.cast(tf.cos(PSF_phase),tf.complex64)-1j*tf.cast(tf.sin(PSF_phase),tf.complex64)\n",
    "\n",
    "#    PSF_phase=2*tf.constant(math.pi, dtype=tf.complex64)*tf.cast(PSF, tf.complex64) #/tf.cast(tf.reduce_max(PSF), tf.complex64)\n",
    "#    with tf.device('/cpu:0'):\n",
    "#        PSF_phase=tf.exp(-1j*PSF_phase)\n",
    "\n",
    "    PSF_phase=fftshift(PSF_phase,m,m)\n",
    "\n",
    "    H = H_fresnel*H_NA*PSF_phase\n",
    "\n",
    "    if incoherent:\n",
    "        #H=np.fft.ifft2(np.abs(np.fft.fft2(H))**2)\n",
    "        #H=tf.ifft2d(tf.fft2d(H)*tf.conj(tf.fft2d(H)))\n",
    "        H=tf.fft2d(tf.ifft2d(H)*tf.conj(tf.ifft2d(H)))\n",
    "        #H=H/H[0,0]\n",
    "\n",
    "        U1=fftshift(u1,m,m)\n",
    "        U1=tf.fft2d(U1)\n",
    "\n",
    "        U2=H*U1\n",
    "        u2=fftshift(tf.ifft2d(U2),m,m)\n",
    "\n",
    "    else:\n",
    "        U1=fftshift(u1,m,m)\n",
    "        U1=tf.fft2d(U1)\n",
    "\n",
    "        U2=H*U1\n",
    "        u2=fftshift(tf.ifft2d(U2),m,m)\n",
    "        u2 = u2*tf.conj(u2) # make into intensity object\n",
    "\n",
    "    return u2\n",
    "\n",
    "\n",
    "def change_filter_function(u1,H_old,H_new,Nx,reg=1e-10,incoherent=1):\n",
    "    \n",
    "    #u1 is the source plane field\n",
    "    #Nx is u1.shape[0]\n",
    "    #dx is L/m\n",
    "    #H_old and H_new are already fftshifted in Fourier space\n",
    "\n",
    "\n",
    "    if incoherent:\n",
    "        H_old = tf.fft2d(tf.ifft2d(H_old)*tf.conj(tf.ifft2d(H_old)))\n",
    "        H_new = tf.fft2d(tf.ifft2d(H_new)*tf.conj(tf.ifft2d(H_new)))\n",
    "        #H=H/H[0,0]\n",
    "\n",
    "        U1=fftshift(u1,Nx,Nx)\n",
    "        U1=tf.fft2d(U1)\n",
    "\n",
    "#        U2=H_old*U1 # previous processing\n",
    "        U2 = (H_new/(H_old+reg))*U1\n",
    "\n",
    "        \n",
    "        u2=fftshift(tf.ifft2d(U2),Nx,Nx)\n",
    "\n",
    "    else:\n",
    "        U1=fftshift(u1,Nx,Nx)\n",
    "        U1=tf.fft2d(U1)\n",
    "\n",
    "        U2=(H_new/(H_old+reg))*U1\n",
    "\n",
    "#        U2=H_old*U1 # previous processing\n",
    "        u2=fftshift(tf.ifft2d(U2),Nx,Nx) # field value\n",
    "#        u2 = u2*np.conj(u2) # make into intensity object\n",
    "\n",
    "    return u2\n",
    "\n",
    "\n",
    "def create_phase_obj_stack(PSF, trainingSet, batch_size, H_fresnel, H_NA, Nx):\n",
    "    for ii in range(batch_size):\n",
    "\n",
    "        # low_res_obj is an intensity object\n",
    "        low_res_obj = propTF_withNA_PSFcustom(trainingSet[ii,:,:],H_fresnel,H_NA,PSF,Nx,incoherent=0)\n",
    "\n",
    "        low_res_obj = tf.expand_dims(low_res_obj,axis=0)\n",
    "\n",
    "        if ii == 0:\n",
    "            low_res_obj_stack = low_res_obj\n",
    "        else:\n",
    "            low_res_obj_stack = tf.concat([low_res_obj_stack,low_res_obj],0)\n",
    "\n",
    "    low_res_obj_stack = tf.cast(low_res_obj_stack, tf.float32)\n",
    "\n",
    "    return low_res_obj_stack\n",
    "\n",
    "\n",
    "def create_microscope_img(PSF,trainingSet_sample,Nz,H_fresnel_stack,H_NA,m,num_wavelengths):\n",
    "    # trainingSet_sample = trainingSet[ii,:,:,:]\n",
    "\n",
    "    microscopeImg=[]\n",
    "\n",
    "    for zInd in range(Nz):\n",
    "        for waveInd in range(num_wavelengths):\n",
    "            add_layer=propTF_withNA_PSFcustom(trainingSet_sample[:,:,zInd,waveInd],H_fresnel_stack[:,:,zInd,waveInd],H_NA[:,:,waveInd],PSF,m)\n",
    "            microscopeImg.append(add_layer)\n",
    "\n",
    "    microscopeImg = tf.add_n(microscopeImg)\n",
    "    microscopeImg = tf.expand_dims(microscopeImg,axis=0)\n",
    "    microscopeImg = tf.cast(microscopeImg, tf.float32)\n",
    "    return microscopeImg\n",
    "\n",
    "\n",
    "def create_microscopeImgStack(PSF,trainingSet,Nz,batch_size,H_fresnel_stack,H_NA,m,num_wavelengths): #creates microscopeImg for every example in the trainingSet\n",
    "    \n",
    "    for ii in range(batch_size):\n",
    "        microscopeImg = create_microscope_img(PSF,trainingSet[ii,:,:,:,:],Nz,H_fresnel_stack,H_NA,m,num_wavelengths)\n",
    "        if ii == 0:\n",
    "            microscopeImgStack = microscopeImg\n",
    "        else:\n",
    "            microscopeImgStack = tf.concat([microscopeImgStack,microscopeImg],0)\n",
    "\n",
    "    return microscopeImgStack\n",
    "\n",
    "\n",
    "def add_noise_microscopeImgStack(microscopeImgStack,normalRandomMat1,normalRandomMat2,sqrt_reg,\\\n",
    "                                 poisson_noise_multiplier, gaussian_noise_multiplier, batch_size, library=tf):\n",
    "\n",
    "    #XXX Fix the Poisson noise for low photon levels\n",
    "    \n",
    "    if library == tf:\n",
    "        multiplierPoisson = tf.constant(poisson_noise_multiplier,dtype=tf.float32) #6e3 for EPFL\n",
    "        multiplierGaussian = tf.constant(gaussian_noise_multiplier,dtype=tf.float32)\n",
    "    else:\n",
    "        multiplierPoisson = poisson_noise_multiplier\n",
    "        multiplierGaussian = gaussian_noise_multiplier\n",
    "    \n",
    "    microscopeImgStack2 = microscopeImgStack*multiplierPoisson\n",
    "\n",
    "    microscopeImgStack3=library.sqrt(library.abs(microscopeImgStack2)+sqrt_reg)*normalRandomMat1+microscopeImgStack2\n",
    "    microscopeImgStack4=microscopeImgStack3+multiplierGaussian*normalRandomMat2\n",
    "\n",
    "    \n",
    "    zeros = library.zeros([batch_size, microscopeImgStack4.shape[1], microscopeImgStack4.shape[2]], dtype=library.float32)\n",
    "\n",
    "    microscopeImgStack = library.where(microscopeImgStack4<0,zeros,microscopeImgStack4) #truncate below 0\n",
    "    \n",
    "    microscopeImgStack = microscopeImgStack/multiplierPoisson\n",
    "    return microscopeImgStack\n",
    "\n",
    "\n",
    "def F(mat2D,dim0,dim1):\n",
    "    return fftshift(tf.fft2d(mat2D),dim0,dim1)\n",
    "\n",
    "def Ft(mat2D,dim0,dim1):\n",
    "    return tf.ifft2d(fftshift(mat2D,dim0,dim1))\n",
    "\n",
    "downsamp = lambda x,cen,Np:  x[cen[0]-Np//2:cen[0]-Np//2+Np, \\\n",
    "    cen[1]-Np//2:cen[1]-Np//2+Np]\n",
    "\n",
    "\n",
    "def sigmoid_stretch(x, stretch, library=tf):\n",
    "    y = 1. / (1. + library.exp(-x/stretch))\n",
    "    return y\n",
    "\n",
    "\n",
    "def HiToLoPatch_singleLED(obj,scale_multiply, Ns, scale, cen0, P, Np, N_obj, LED_i): #stretch\n",
    "\n",
    "    illumination_weight = scale[LED_i] * scale_multiply[LED_i]\n",
    "\n",
    "\n",
    "    cen = (cen0-Ns[LED_i,:]).astype(int) \n",
    "    O=F(obj,N_obj,N_obj)\n",
    "\n",
    "    Psi0 = downsamp(O,cen,Np)*P\n",
    "\n",
    "    psi0 = Ft(Psi0,Np,Np) #low resolution field\n",
    "    intensity_i = psi0*tf.conj(psi0)*tf.cast(illumination_weight, tf.complex64)\n",
    "\n",
    "    return intensity_i\n",
    "\n",
    "\n",
    "def HiToLo_singleLED(obj, N_obj, N_patch, scale_multiply, num_patches, Ns_mat, scale_mat, \\\n",
    "           cen0, P, Np, LED_i):\n",
    "\n",
    "    low_res_patches=[]\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    for i,startX in enumerate(np.arange(0,N_obj,N_patch)):\n",
    "        for j,startY in enumerate(np.arange(0,N_obj,N_patch)):\n",
    "\n",
    "            # pass the full object to HiToLoPatch\n",
    "            Ns = Ns_mat[count,:,:]\n",
    "            scale = scale_mat[count,:]\n",
    "            low_res_patch_everything = HiToLoPatch_singleLED(obj,scale_multiply, Ns, scale, cen0, P, Np, N_obj, LED_i)\n",
    "            low_res_patches.append(low_res_patch_everything)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "    count = 0\n",
    "\n",
    "\n",
    "    for i,startX in enumerate(np.arange(0,Np,Np/num_patches)):\n",
    "        for j,startY in enumerate(np.arange(0,Np,Np/num_patches)):\n",
    "            # Extract out patch of interest\n",
    "            low_res_patch=tf.slice(low_res_patches[count],[int(startX),int(startY)],[int(N_patch*Np/N_obj),int(N_patch*Np/N_obj)])\n",
    "            if j==0:\n",
    "                low_res_obj_row=low_res_patch\n",
    "            else:\n",
    "                low_res_obj_row = tf.concat([low_res_obj_row,low_res_patch],axis=1)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        if i==0:\n",
    "            low_res_obj = low_res_obj_row\n",
    "        else:\n",
    "            low_res_obj = tf.concat([low_res_obj,low_res_obj_row],axis=0)\n",
    "\n",
    "    low_res_obj = tf.cast(low_res_obj,tf.float32)\n",
    "    return low_res_obj\n",
    "\n",
    "\n",
    "\n",
    "def HiToLoPatch(obj,scale_multiply, Ns, scale, cen0, P, H0, Np, N_obj, numLEDs): #stretch\n",
    "\n",
    "    illumination_weights = scale * scale_multiply #sigmoid_stretch(scale_multiply,stretch) #scale_multiply\n",
    "\n",
    "    for LED_i in range(numLEDs):\n",
    "        cen = (cen0-Ns[LED_i,:]).astype(int)\n",
    "        O=F(obj,N_obj,N_obj)\n",
    "\n",
    "        Psi0 = downsamp(O*H0,cen,Np)*P\n",
    "\n",
    "        psi0 = Ft(Psi0,Np,Np) #low resolution field\n",
    "        intensity_i = psi0*tf.conj(psi0)*tf.cast(illumination_weights[LED_i], tf.complex64)\n",
    "\n",
    "        if LED_i == 0:\n",
    "            low_res_patch = intensity_i\n",
    "        else:\n",
    "            low_res_patch = low_res_patch + intensity_i\n",
    "\n",
    "    return low_res_patch\n",
    "\n",
    "def HiToLo(obj, N_obj, N_patch, scale_multiply, num_patches, Ns_mat, scale_mat, \\\n",
    "           cen0, P, H0, Np, numLEDs): #stretch\n",
    "\n",
    "    low_res_patches=[]\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    for i,startX in enumerate(np.arange(0,N_obj,N_patch)):\n",
    "        for j,startY in enumerate(np.arange(0,N_obj,N_patch)):\n",
    "\n",
    "            # pass the full object to HiToLoPatch\n",
    "            Ns = Ns_mat[count,:,:]\n",
    "            scale = scale_mat[count,:]\n",
    "            low_res_patch_everything = HiToLoPatch(obj,scale_multiply, Ns, scale, cen0, P, H0, Np, N_obj, numLEDs) #stretch\n",
    "            low_res_patches.append(low_res_patch_everything)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "    count = 0\n",
    "\n",
    "\n",
    "    for i,startX in enumerate(np.arange(0,Np,Np/num_patches)):\n",
    "        for j,startY in enumerate(np.arange(0,Np,Np/num_patches)):\n",
    "            # Extract out patch of interest\n",
    "            low_res_patch=tf.slice(low_res_patches[count],[int(startX),int(startY)],[int(N_patch*Np/N_obj),int(N_patch*Np/N_obj)])\n",
    "            if j==0:\n",
    "                low_res_obj_row=low_res_patch\n",
    "            else:\n",
    "                low_res_obj_row = tf.concat([low_res_obj_row,low_res_patch],axis=1)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        if i==0:\n",
    "            low_res_obj = low_res_obj_row\n",
    "        else:\n",
    "            low_res_obj = tf.concat([low_res_obj,low_res_obj_row],axis=0)\n",
    "\n",
    "    return low_res_obj\n",
    "\n",
    "def upsample(low_res_obj, Np, N_obj):\n",
    "    \n",
    "    if Np == 1:\n",
    "        dense_multiply = tf.cast(tf.squeeze(getConvInitializer(N_obj, N_obj, init_type=\"trunc_norm\")), tf.complex64)\n",
    "        dense_bias = tf.cast(tf.squeeze(getConvInitializer(N_obj, N_obj, init_type=\"trunc_norm\")), tf.complex64)\n",
    "        \n",
    "#        dense_multiply_i = tf.cast(tf.squeeze(getConvInitializer(N_obj, N_obj, init_type=\"trunc_norm\")), tf.complex64)\n",
    "#        dense_bias_i = tf.cast(tf.squeeze(getConvInitializer(N_obj, N_obj, init_type=\"trunc_norm\")), tf.complex64)\n",
    "        \n",
    "        \n",
    "#        pad0 = (N_obj - Np)//2 -1\n",
    "#        pad1 = pad0 + 3\n",
    "#        upsampled_obj = tf.pad(upsampled_obj, [[int(pad0),int(pad1)],[int(pad0),int(pad1)]], 'CONSTANT', \\\n",
    "#                                                constant_values = 100)\n",
    "#        upsampled_obj_real = low_res_obj*dense_multiply_r + dense_bias_r\n",
    "#        upsampled_obj_imag = low_res_obj*dense_multiply_i + dense_bias_i\n",
    "        upsampled_obj = low_res_obj*dense_multiply + dense_bias\n",
    "#        upsampled_obj = tf.Print(upsampled_obj, [dense_multiply], message='dense_multiply: ')\n",
    "#        upsampled_obj = tf.Print(upsampled_obj, [dense_bias], message='dense_bias: ')\n",
    "#        upsampled_obj = tf.Print(upsampled_obj, [low_res_obj], message='low_res_obj: ')\n",
    "\n",
    "    else:    \n",
    "        upsampled_obj = F(low_res_obj,Np,Np)\n",
    "        pad = (N_obj - Np)/2\n",
    "        upsampled_obj = tf.pad(upsampled_obj, [[int(pad),int(pad)],[int(pad),int(pad)]], 'CONSTANT')\n",
    "        upsampled_obj = Ft(upsampled_obj,N_obj,N_obj)\n",
    "\n",
    "    return upsampled_obj\n",
    "\n",
    "def create_upsampled_obj_stack(low_res_obj_stack, batch_size, Np, N_obj):\n",
    "    low_res_obj_stack = tf.cast(low_res_obj_stack, tf.complex64)\n",
    "    for ii in range(batch_size):\n",
    "        upsampled_obj = upsample(low_res_obj_stack[ii,:,:], Np, N_obj)\n",
    "        upsampled_obj = tf.expand_dims(upsampled_obj,axis=0)\n",
    "        if ii == 0:\n",
    "            upsampled_obj_stack = upsampled_obj\n",
    "        else:\n",
    "            upsampled_obj_stack = tf.concat([upsampled_obj_stack,upsampled_obj],0)\n",
    "\n",
    "    upsampled_obj_stack = tf.cast(upsampled_obj_stack, tf.float32)\n",
    "    return upsampled_obj_stack\n",
    "\n",
    "def create_FP_img_stack(scale_multiply,trainingSet,batch_size, N_obj, N_patch, num_patches, Ns_mat, \\\n",
    "                        scale_mat, cen0, P, H0, Np, numLEDs): \n",
    "    for ii in range(batch_size):\n",
    "        low_res_obj = HiToLo(trainingSet[ii,:,:], N_obj, N_patch, scale_multiply, \\\n",
    "                             num_patches, Ns_mat, scale_mat, \\\n",
    "                             cen0, P, H0, Np, numLEDs)\n",
    "\n",
    "        low_res_obj = tf.expand_dims(low_res_obj,axis=0)\n",
    "\n",
    "        if ii == 0:\n",
    "            low_res_obj_stack = low_res_obj\n",
    "        else:\n",
    "            low_res_obj_stack = tf.concat([low_res_obj_stack,low_res_obj],0)\n",
    "\n",
    "    low_res_obj_stack = tf.cast(low_res_obj_stack, tf.float32)\n",
    "    return low_res_obj_stack\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_loss_FP(predicted_mat, trainingSet, library = tf):\n",
    "\n",
    "    if library == tf:\n",
    "        sum_func = tf.reduce_sum\n",
    "    else:\n",
    "        sum_func = np.sum\n",
    "        \n",
    "    loss_l2 = sum_func(library.real((predicted_mat - trainingSet)*library.conj(predicted_mat - trainingSet)))\n",
    "#    loss_l1 = sum_func(library.abs(predicted_mat - trainingSet))\n",
    "\n",
    "    return loss_l2\n",
    "\n",
    "\n",
    "def grad_diff_loss(predicted_mat, trainingSet, library = tf):\n",
    "\n",
    "    if library == tf:\n",
    "        sum_func = tf.reduce_sum\n",
    "    else:\n",
    "        sum_func = np.sum\n",
    "    \n",
    "    diff_x_actual = trainingSet[:,1:,:]-trainingSet[:,:-1,:]\n",
    "    diff_y_actual = trainingSet[:,:,1:]-trainingSet[:,:,:-1]\n",
    "\n",
    "    diff_x_guess = predicted_mat[:,1:,:]-predicted_mat[:,:-1,:]\n",
    "    diff_y_guess= predicted_mat[:,:,1:]-predicted_mat[:,:,:-1]\n",
    "\n",
    "    loss_x = sum_func(library.real((diff_x_actual-diff_x_guess)*library.conj(diff_x_actual-diff_x_guess)))\n",
    "    loss_y = sum_func(library.real((diff_y_actual-diff_y_guess)*library.conj(diff_y_actual-diff_y_guess)))\n",
    "\n",
    "    return loss_x + loss_y\n",
    "\n",
    "def convert_net_prediction_list(net_prediction_list, image_modality, batch_size, optical_parameters_dict):\n",
    "    if (image_modality == 'FP') or (image_modality == 'phase') or (image_modality == 'FP_PP'):\n",
    "\n",
    "        predicted_mat = tf.cast(net_prediction_list[0],tf.complex64)+1j*tf.cast(net_prediction_list[1],tf.complex64)\n",
    "#        predicted_mat = tf.cast(net_prediction_list[0],tf.complex64)*tf.exp(1j*tf.cast(net_prediction_list[1],tf.complex64))\n",
    "\n",
    "        predicted_mat = tf.squeeze(predicted_mat,axis=3)\n",
    "\n",
    "    elif image_modality == 'STORM':\n",
    "        Nx = optical_parameters_dict['Nx_highres']\n",
    "        Nz = optical_parameters_dict['Nz']\n",
    "        num_wavelengths = optical_parameters_dict['num_wavelengths']\n",
    "        \n",
    "        predicted_mat = tf.stack(net_prediction_list,axis=3)\n",
    "        predicted_mat = tf.reshape(predicted_mat, [batch_size, Nx, Nx, Nz, num_wavelengths])\n",
    "        \n",
    "    elif image_modality == 'HE':         \n",
    "        predicted_mat = tf.stack(net_prediction_list,axis=3)\n",
    "\n",
    "        predicted_mat = tf.squeeze(predicted_mat, axis = 4)\n",
    "\n",
    "\n",
    "    return predicted_mat\n",
    "\n",
    "def iterative_solver_FP(predicted_mat, optical_element, batch_size, N_obj, N_patch, num_patches, Ns_mat,\\\n",
    "                        scale_mat, cen0, P, H0, Np, numLEDs, low_res_obj_stack, step_size, max_internal_iter, \\\n",
    "                        merit_stopping_point, loss_low_res, i):\n",
    "\n",
    "#    print 'mii2'\n",
    "    predicted_mat_real = tf.real(predicted_mat)\n",
    "    predicted_mat_imag = tf.imag(predicted_mat)\n",
    "\n",
    "    def single_iter(predicted_mat_real, predicted_mat_imag, loss_low_res, i):\n",
    "\n",
    "        predicted_mat = tf.cast(predicted_mat_real,tf.complex64)+1j*tf.cast(predicted_mat_imag,tf.complex64)\n",
    "        low_res_obj_predicted = create_FP_img_stack(optical_element,predicted_mat,batch_size, N_obj, N_patch, num_patches, Ns_mat, \\\n",
    "                        scale_mat, cen0, P, H0, Np, numLEDs) #stretch\n",
    "\n",
    "        loss_low_res = tf.reduce_sum(tf.square(low_res_obj_stack - low_res_obj_predicted))\n",
    "\n",
    "#        loss_MSE = calculate_loss_FP(low_res_obj_predicted, low_res_obj_stack)\n",
    "#        loss_grad = grad_diff_loss(low_res_obj_predicted, low_res_obj_stack)\n",
    "        \n",
    "\n",
    "        #find gradient of loss_low_res with respect to predicted_mat\n",
    "        predicted_mat_real_gradient = tf.squeeze(tf.gradients(loss_low_res,predicted_mat_real),axis=0)\n",
    "        predicted_mat_imag_gradient = tf.squeeze(tf.gradients(loss_low_res,predicted_mat_imag),axis=0)\n",
    "\n",
    "#        predicted_mat_real_gradient = tf.Print(predicted_mat_real_gradient, [loss_low_res], message='loss_low_res: ')\n",
    "\n",
    "        #update predicted_mat with step_size\n",
    "        predicted_mat_real = predicted_mat_real - step_size*predicted_mat_real_gradient\n",
    "        predicted_mat_imag = predicted_mat_imag - step_size*predicted_mat_imag_gradient\n",
    "\n",
    "        i+=1\n",
    "\n",
    "        return predicted_mat_real, predicted_mat_imag, loss_low_res, i\n",
    "\n",
    "    def convergence_cond(predicted_mat_real, predicted_mat_imag, loss_low_res,i):\n",
    "        result = True\n",
    "        \n",
    "        \n",
    "#        result = tf.Print(result, [result], message='result1: ')\n",
    "       \n",
    "        result = tf.cond(i>=max_internal_iter, lambda: False, lambda: result)\n",
    "        \n",
    "#        result = tf.Print(result, [result], message='result2: ')\n",
    "        \n",
    "        result = tf.cond(loss_low_res<merit_stopping_point, lambda: False, lambda: result)\n",
    "        \n",
    "#        result = tf.Print(result, [result], message='result3: ')\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "    [predicted_mat_real, predicted_mat_imag, loss_low_res, i] = tf.while_loop(convergence_cond,\n",
    "                                                                              single_iter,\n",
    "                                                                              [predicted_mat_real, predicted_mat_imag, loss_low_res,i])\n",
    "\n",
    "\n",
    "    predicted_mat = tf.cast(predicted_mat_real,tf.complex64)+1j*tf.cast(predicted_mat_imag,tf.complex64)\n",
    "\n",
    "    return predicted_mat\n",
    "\n",
    "def iterative_solver_STORM(predicted_mat, PSF, Nz,batch_size, H_fresnel_stack, \\\n",
    "                           H_NA, Nx, low_res_obj_stack, step_size, max_internal_iter, \\\n",
    "                           merit_stopping_point, loss_low_res, i, num_wavelengths):\n",
    "\n",
    "    def single_iter(predicted_mat, loss_low_res, i):\n",
    "\n",
    "        predicted_mat_complex=tf.cast(predicted_mat, tf.complex64)\n",
    "        low_res_obj_predicted = create_microscopeImgStack(PSF,predicted_mat_complex,Nz,batch_size,H_fresnel_stack,H_NA,Nx,num_wavelengths)\n",
    "\n",
    "        loss_low_res = tf.reduce_sum(tf.square(low_res_obj_stack - low_res_obj_predicted))\n",
    "\n",
    "        #find gradient of loss_low_res with respect to predicted_mat\n",
    "        predicted_mat_gradient = tf.squeeze(tf.gradients(loss_low_res,predicted_mat),axis=0)\n",
    "\n",
    "    #            predicted_mat_gradient = tf.Print(predicted_mat_gradient, [loss_low_res], message='loss_low_res: ')\n",
    "\n",
    "        #update predicted_mat with step_size\n",
    "        predicted_mat = predicted_mat - step_size*predicted_mat_gradient\n",
    "\n",
    "        i+=1\n",
    "\n",
    "        return predicted_mat, loss_low_res, i\n",
    "\n",
    "    def convergence_cond(predicted_mat, loss_low_res,i):\n",
    "        result = True\n",
    "        result = tf.cond(i>=max_internal_iter, lambda: False, lambda: result)\n",
    "        result = tf.cond(loss_low_res<merit_stopping_point, lambda: False, lambda: result)\n",
    "        return result\n",
    "\n",
    "\n",
    "    [predicted_mat, loss_low_res, i] = tf.while_loop(convergence_cond,\n",
    "                                                    single_iter,\n",
    "                                                    [predicted_mat, loss_low_res,i])\n",
    "    return predicted_mat\n",
    "\n",
    "\n",
    "def iterative_solver_phase(predicted_mat, PSF, batch_size, H_fresnel, \\\n",
    "                           H_NA, Nx, low_res_obj_stack, step_size, max_internal_iter, \\\n",
    "                           merit_stopping_point, loss_low_res, i):\n",
    "\n",
    "    predicted_mat_real = tf.real(predicted_mat)\n",
    "    predicted_mat_imag = tf.imag(predicted_mat)\n",
    "\n",
    "    def single_iter(predicted_mat_real, predicted_mat_imag, loss_low_res, i):\n",
    "\n",
    "        predicted_mat = tf.cast(predicted_mat_real,tf.complex64)+1j*tf.cast(predicted_mat_imag,tf.complex64)\n",
    "        low_res_obj_predicted = create_phase_obj_stack(PSF, predicted_mat, batch_size, H_fresnel, H_NA, Nx)\n",
    "\n",
    "        loss_low_res = tf.reduce_sum(tf.square(low_res_obj_stack - low_res_obj_predicted))\n",
    "\n",
    "        #find gradient of loss_low_res with respect to predicted_mat\n",
    "        predicted_mat_real_gradient = tf.squeeze(tf.gradients(loss_low_res,predicted_mat_real),axis=0)\n",
    "        predicted_mat_imag_gradient = tf.squeeze(tf.gradients(loss_low_res,predicted_mat_imag),axis=0)\n",
    "\n",
    "        #update predicted_mat with step_size\n",
    "        predicted_mat_real = predicted_mat_real - step_size*predicted_mat_real_gradient\n",
    "        predicted_mat_imag = predicted_mat_imag - step_size*predicted_mat_imag_gradient\n",
    "\n",
    "        i+=1\n",
    "\n",
    "        return predicted_mat_real, predicted_mat_imag, loss_low_res, i\n",
    "\n",
    "    def convergence_cond(predicted_mat_real, predicted_mat_imag, loss_low_res,i):\n",
    "        result = True\n",
    "        result = tf.cond(i>=max_internal_iter, lambda: False, lambda: result)\n",
    "        result = tf.cond(loss_low_res<merit_stopping_point, lambda: False, lambda: result)\n",
    "        return result\n",
    "\n",
    "\n",
    "    [predicted_mat_real, predicted_mat_imag, loss_low_res, i] = tf.while_loop(convergence_cond,\n",
    "                                                                              single_iter,\n",
    "                                                                              [predicted_mat_real, predicted_mat_imag, loss_low_res,i])\n",
    "\n",
    "\n",
    "    predicted_mat = tf.cast(predicted_mat_real,tf.complex64)+1j*tf.cast(predicted_mat_imag,tf.complex64)\n",
    "\n",
    "\n",
    "    return predicted_mat\n",
    "\n",
    "\n",
    "def iterative_solver_HE(predicted_mat, Nx_highres, h_blur, \\\n",
    "                       high_magn, low_magn, dpix_c, wavelength, \\\n",
    "                       low_NA, low_res_obj_batch, step_size, max_internal_iter, \\\n",
    "                       merit_stopping_point, loss_low_res, i, \\\n",
    "                       batch_size):\n",
    "\n",
    "    def single_iter(predicted_mat, loss_low_res, i):\n",
    "\n",
    "        low_res_obj_batch_predicted = change_magn_batch(predicted_mat, Nx_highres, h_blur, \\\n",
    "                                                        high_magn, low_magn, dpix_c, wavelength, low_NA, batch_size)\n",
    "\n",
    "\n",
    "\n",
    "        low_res_obj_batch_predicted = tf.cast(low_res_obj_batch_predicted, tf.float32)\n",
    "\n",
    "        loss_low_res = tf.reduce_sum(tf.square(low_res_obj_batch - low_res_obj_batch_predicted))\n",
    "\n",
    "        #find gradient of loss_low_res with respect to predicted_mat\n",
    "\n",
    "        predicted_mat_gradient = tf.squeeze(tf.gradients(loss_low_res,predicted_mat),axis=0)\n",
    "\n",
    "#            predicted_mat_gradient = tf.Print(predicted_mat_gradient, [predicted_mat_gradient], message='predicted_mat_gradient: ')\n",
    "#            predicted_mat_gradient = tf.Print(predicted_mat_gradient, [loss_low_res], message='loss_low_res: ')\n",
    "\n",
    "        #update predicted_mat with step_size\n",
    "        predicted_mat = predicted_mat - step_size*predicted_mat_gradient\n",
    "\n",
    "        i+=1\n",
    "\n",
    "        return predicted_mat, loss_low_res, i\n",
    "\n",
    "    def convergence_cond(predicted_mat, loss_low_res,i):\n",
    "        result = True\n",
    "        result = tf.cond(i>=max_internal_iter, lambda: False, lambda: result)\n",
    "        result = tf.cond(loss_low_res<merit_stopping_point, lambda: False, lambda: result)\n",
    "        return result\n",
    "\n",
    "\n",
    "    [predicted_mat, loss_low_res, i] = tf.while_loop(convergence_cond,\n",
    "                                                     single_iter,\n",
    "                                                     [predicted_mat, loss_low_res,i])\n",
    "\n",
    "\n",
    "    return predicted_mat, loss_low_res\n",
    "\n",
    "\n",
    "def find_predicted_mat(image_modality, num_nets, input_layer_list, Nx, batch_size, layers_dropout, dropout_prob,\n",
    "                       use_batch_norm, autoencode_init_type, init_type_bias, init_type_resid, kernel_multiplier, variance_reg, training, \\\n",
    "                       num_layers_autoencode, skip_interval, num_blocks, optical_parameters_dict):\n",
    "\n",
    "    net_prediction_list = []\n",
    "    for net in range(num_nets):\n",
    "        with tf.variable_scope(\"net_\" + str(net)):\n",
    "\n",
    "            curr_input = input_layer_list[net]\n",
    "            for i in range(num_blocks):\n",
    "                with tf.variable_scope(\"ae_\" + str(i)):\n",
    "                    curr_net = AutoEncoder(curr_input, \n",
    "                                           num_layers_autoencode, Nx,\n",
    "                                           batch_size, training,\n",
    "                                           kernel_multiplier, \n",
    "                                           skip_interval=skip_interval, \n",
    "                                           conv_activation='maxout',\n",
    "                                           deconv_activation='maxout',\n",
    "                                           dropout_count=layers_dropout, \n",
    "                                           dropout_prob=dropout_prob,\n",
    "                                           create_graph_viz=False, \n",
    "                                           use_batch_norm=use_batch_norm,\n",
    "                                           init_type=autoencode_init_type, \n",
    "                                           init_type_bias=init_type_bias, \n",
    "                                           init_type_resid=init_type_resid)\n",
    "                    curr_input = curr_net.get_prediction()\n",
    "            net0_prediction = curr_input\n",
    "            net_prediction_list.append(net0_prediction)\n",
    "            \n",
    "            \"\"\"\n",
    "            with tf.variable_scope(\"ae_0\"):\n",
    "                net_init = AutoEncoder(input_layer_list[net], num_layers_autoencode, Nx, batch_size, training, \\\n",
    "                                           kernel_multiplier, skip_interval=skip_interval, conv_activation='maxout', \\\n",
    "                                           deconv_activation='maxout', dropout_count=layers_dropout, dropout_prob=dropout_prob, \\\n",
    "                                           create_graph_viz=False, use_batch_norm=use_batch_norm, \\\n",
    "                                           init_type=autoencode_init_type, init_type_bias=init_type_bias, init_type_resid=init_type_resid)\n",
    "                net_init_prediction = net_init.get_prediction()\n",
    "\n",
    "            with tf.variable_scope(\"ae_1\"):\n",
    "                net0 = AutoEncoder(net_init_prediction, num_layers_autoencode, Nx, batch_size, training, \\\n",
    "                                       kernel_multiplier, skip_interval=skip_interval, conv_activation='maxout', \\\n",
    "                                       deconv_activation='maxout', dropout_count=layers_dropout, dropout_prob=dropout_prob, \\\n",
    "                                       create_graph_viz=False, use_batch_norm=use_batch_norm, \\\n",
    "                                       init_type=autoencode_init_type, init_type_bias=init_type_bias, init_type_resid=init_type_resid)\n",
    "                net0_prediction = net0.get_prediction()\n",
    "                net_prediction_list.append(net0_prediction)\n",
    "            \"\"\"\n",
    "                \n",
    "    ### End Neural Network(s)\n",
    "\n",
    "    ### Convert net_prediction_list to predicted_mat\n",
    "\n",
    "    predicted_mat = convert_net_prediction_list(net_prediction_list, image_modality, batch_size, optical_parameters_dict)\n",
    "\n",
    "    return predicted_mat\n",
    "\n",
    "\n",
    "def tower_loss_all(trainingSet, training, normalRandomMat1, normalRandomMat2, \\\n",
    "               initialize_optical_element_ones, num_elements, use_batch_norm, variance_reg, add_noise, sqrt_reg, \\\n",
    "               dropout_prob, layers_dropout, batch_size, max_internal_iter, merit_stopping_point, optical_parameters_dict, \\\n",
    "               autoencode_init_type, init_type_bias, init_type_resid, \\\n",
    "               kernel_multiplier, \\\n",
    "               poisson_noise_multiplier, gaussian_noise_multiplier, image_modality,\n",
    "               num_layers_autoencode, skip_interval, num_blocks, \\\n",
    "               training_data_folder, load_optical_element_init,\n",
    "               lowres_trainingSet=None):\n",
    "\n",
    "    with tf.variable_scope(\"optical_transform\"):\n",
    "\n",
    "        Nx = optical_parameters_dict['Nx_highres']\n",
    "        Nz = optical_parameters_dict['Nz']\n",
    "\n",
    "        if initialize_optical_element_ones:\n",
    "            if (image_modality == 'FP') or (image_modality == 'FP_PP'):\n",
    "                optical_element0 = np.ones([num_elements,], dtype=np.float32)\n",
    "            elif (image_modality == 'STORM') or (image_modality == 'phase'):\n",
    "                optical_element0 = np.zeros([num_elements,], dtype=np.float32)\n",
    "                optical_element0[0] = 1\n",
    "        elif load_optical_element_init:\n",
    "            optical_element0 = np.load(training_data_folder + '/optical_element_init.npy')\n",
    "            \n",
    "        else:\n",
    "            optical_element0 = np.random.rand(num_elements,).astype(np.float32)\n",
    "\n",
    "        if image_modality == 'FP':\n",
    "\n",
    "            optical_element = variable_on_cpu('optical_element', optical_element0, tf.float32, \\\n",
    "                                              constraint = lambda x: tf.clip_by_value(x, 0, 1.0))\n",
    "\n",
    "\n",
    "#            optical_element = variable_on_cpu('optical_element', optical_element0, tf.float32) #stretch\n",
    "\n",
    "\n",
    "            num_nets = 2 # one neural net for real and one for imaginary\n",
    "\n",
    "            numLEDs = optical_parameters_dict['numLEDs']\n",
    "            N_obj = optical_parameters_dict['N_obj']\n",
    "            N_patch = optical_parameters_dict['N_patch']\n",
    "            num_patches = optical_parameters_dict['num_patches']\n",
    "            Ns_mat = optical_parameters_dict['Ns_mat']\n",
    "            scale_mat = optical_parameters_dict['scale_mat']\n",
    "            cen0 = optical_parameters_dict['cen0']\n",
    "            P = optical_parameters_dict['P']\n",
    "            H0 = optical_parameters_dict['H0']\n",
    "            Np = optical_parameters_dict['Np']\n",
    "\n",
    "#            stretch = variable_on_cpu('sigmoid_stretch', 1.0, tf.float32, trainable=False)\n",
    "\n",
    "            ### Convert trainingSet to low resolution\n",
    "\n",
    "            low_res_obj_stack = create_FP_img_stack(optical_element,trainingSet,batch_size, N_obj, N_patch, num_patches, Ns_mat, \\\n",
    "                            scale_mat, cen0, P, H0, Np, numLEDs) #stretch\n",
    "\n",
    "        elif image_modality == 'FP_PP':\n",
    "            \n",
    "            numLEDs = optical_parameters_dict['numLEDs']\n",
    "            N_obj = optical_parameters_dict['N_obj']\n",
    "            Np = optical_parameters_dict['Np']\n",
    "            N_patch = optical_parameters_dict['N_patch']\n",
    "            num_patches = optical_parameters_dict['num_patches']\n",
    "            Ns_mat = optical_parameters_dict['Ns_mat']\n",
    "            scale_mat = optical_parameters_dict['scale_mat']\n",
    "            cen0 = optical_parameters_dict['cen0']\n",
    "            P = optical_parameters_dict['P']\n",
    "            H0 = optical_parameters_dict['H0']        \n",
    "            \n",
    "            optical_element = variable_on_cpu('optical_element', optical_element0, tf.float32, \\\n",
    "                                              constraint = lambda x: tf.clip_by_value(x, 0, 1.0))\n",
    "                        \n",
    "            num_nets = 2 # one neural net for real and one for imaginary\n",
    "            \n",
    "            low_res_obj_stack = lowres_trainingSet*optical_element\n",
    "            low_res_obj_stack = tf.reduce_sum(low_res_obj_stack, axis=-1)\n",
    "            \n",
    "        elif image_modality == 'STORM':\n",
    "\n",
    "            optical_element = variable_on_cpu('optical_element', optical_element0, tf.float32)\n",
    "\n",
    "            num_wavelengths = optical_parameters_dict['num_wavelengths']\n",
    "            num_nets = Nz*num_wavelengths\n",
    "\n",
    "            H_fresnel_stack = optical_parameters_dict['H_fresnel_stack']\n",
    "            H_NA = optical_parameters_dict['H_NA']\n",
    "            ZernikePolyMat = optical_parameters_dict['ZernikePolyMat']\n",
    "\n",
    "\n",
    "            PSF = ZernikePolyMat*optical_element\n",
    "            PSF = tf.reduce_sum(PSF,axis=2)\n",
    "\n",
    "            # Process 3D matrices to create the two-dimensional image\n",
    "\n",
    "            low_res_obj_stack = create_microscopeImgStack(PSF, tf.cast(trainingSet, tf.complex64), Nz, batch_size, H_fresnel_stack, H_NA, Nx, num_wavelengths)\n",
    "\n",
    "        elif image_modality == 'phase':\n",
    "\n",
    "            optical_element = variable_on_cpu('optical_element', optical_element0, tf.float32)\n",
    "            num_nets = 2 # one neural net for real and one for imaginary\n",
    "\n",
    "            H_fresnel = optical_parameters_dict['H_fresnel']\n",
    "            H_NA = optical_parameters_dict['H_NA']\n",
    "            ZernikePolyMat = optical_parameters_dict['ZernikePolyMat']\n",
    "\n",
    "            PSF = ZernikePolyMat*optical_element\n",
    "            PSF = tf.reduce_sum(PSF,axis=2)\n",
    "\n",
    "            low_res_obj_stack = create_phase_obj_stack(PSF, trainingSet, batch_size, H_fresnel, H_NA, Nx)\n",
    "\n",
    "\n",
    "\n",
    "        low_res_obj_stack_nonoise = low_res_obj_stack\n",
    "\n",
    "        if add_noise:\n",
    "            low_res_obj_stack=add_noise_microscopeImgStack(low_res_obj_stack, normalRandomMat1, normalRandomMat2,\\\n",
    "                                                           sqrt_reg, poisson_noise_multiplier, gaussian_noise_multiplier, \\\n",
    "                                                           batch_size)\n",
    "\n",
    "\n",
    "        if (image_modality == 'FP') or (image_modality == 'FP_PP'):\n",
    "            # upsample the low_res_obj_stack for FP modality\n",
    "            input_layer = create_upsampled_obj_stack(low_res_obj_stack, batch_size, Np, N_obj)\n",
    "            input_layer = tf.expand_dims(input_layer, axis=3)\n",
    "#            input_layer = tf.sqrt( (input_layer + sqrt_reg) / numLEDs)\n",
    "\n",
    "        elif (image_modality == 'STORM') or (image_modality == 'phase'):\n",
    "            input_layer = tf.expand_dims(low_res_obj_stack, axis=3)\n",
    "\n",
    "    ### Neural Network(s)\n",
    "\n",
    "    with tf.variable_scope(\"neural_net\"):\n",
    "        \n",
    "        input_layer_list = [input_layer for i in range(num_nets)]    \n",
    "        predicted_mat = find_predicted_mat(image_modality, num_nets, input_layer_list, Nx, batch_size, layers_dropout, dropout_prob, \\\n",
    "                               use_batch_norm, autoencode_init_type, init_type_bias, init_type_resid, kernel_multiplier, variance_reg, training, \\\n",
    "                               num_layers_autoencode, skip_interval, num_blocks, optical_parameters_dict)\n",
    "\n",
    "        if (image_modality == 'FP_PP') and (max_internal_iter == 0):\n",
    "            \n",
    "            loss = calculate_loss_FP(predicted_mat, trainingSet)\n",
    "            \n",
    "        else:    \n",
    "            ### convert predicted_mat down to low_res_obj_predicted\n",
    "            if (image_modality == 'FP') or (image_modality == 'FP_PP'):\n",
    "    \n",
    "                low_res_obj_predicted = create_FP_img_stack(optical_element,predicted_mat,batch_size, N_obj, N_patch, num_patches, Ns_mat, \\\n",
    "                                scale_mat, cen0, P, H0, Np, numLEDs) #stretch\n",
    "    \n",
    "            elif image_modality == 'STORM':\n",
    "    \n",
    "                predicted_mat_complex=tf.cast(predicted_mat, tf.complex64)\n",
    "                low_res_obj_predicted = create_microscopeImgStack(PSF,predicted_mat_complex,Nz,batch_size,H_fresnel_stack,H_NA,Nx,num_wavelengths)\n",
    "    \n",
    "            elif image_modality == 'phase':\n",
    "    \n",
    "                low_res_obj_predicted = create_phase_obj_stack(PSF, predicted_mat, batch_size, H_fresnel, H_NA, Nx)\n",
    "    \n",
    "            loss_low_res = tf.reduce_sum(tf.square(low_res_obj_stack - low_res_obj_predicted))\n",
    "    \n",
    "    ###################\n",
    "            step_size = variable_on_cpu('step_size', 1e-7, tf.float32, trainable = False) # XXX make step_size trainable\n",
    "    \n",
    "        \n",
    "            i = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "\n",
    "            if (image_modality == 'FP') or (image_modality == 'FP_PP'):\n",
    "#                print 'mii4'\n",
    "                if max_internal_iter > 0:    \n",
    "#                    print 'mii3'\n",
    "                    predicted_mat = iterative_solver_FP(predicted_mat, optical_element, batch_size, N_obj, N_patch, num_patches, Ns_mat,\\\n",
    "                                scale_mat, cen0, P, H0, Np, numLEDs, low_res_obj_stack, step_size, max_internal_iter, \\\n",
    "                                merit_stopping_point, loss_low_res, i)\n",
    "    \n",
    "                loss = calculate_loss_FP(predicted_mat, trainingSet)\n",
    "    \n",
    "            elif image_modality == 'STORM':\n",
    "                if max_internal_iter > 0:\n",
    "                    predicted_mat = iterative_solver_STORM(predicted_mat, PSF, Nz,batch_size, H_fresnel_stack, \\\n",
    "                                   H_NA, Nx, low_res_obj_stack, step_size, max_internal_iter, \\\n",
    "                                   merit_stopping_point, loss_low_res, i, num_wavelengths)\n",
    "    \n",
    "                loss = tf.reduce_sum(tf.square(predicted_mat - tf.cast(trainingSet, tf.float32))) #l2 loss\n",
    "                \n",
    "\n",
    "            elif image_modality == 'phase':\n",
    "    \n",
    "                if max_internal_iter > 0:\n",
    "                    predicted_mat = iterative_solver_phase(predicted_mat, PSF, batch_size, H_fresnel, \\\n",
    "                                   H_NA, Nx, low_res_obj_stack, step_size, max_internal_iter, \\\n",
    "                                   merit_stopping_point, loss_low_res, i)\n",
    "    \n",
    "                loss = calculate_loss_FP(predicted_mat, trainingSet)\n",
    "\n",
    "            \n",
    "        loss_grad = grad_diff_loss(predicted_mat, trainingSet)\n",
    "\n",
    "    return loss, loss_grad, optical_element, low_res_obj_stack_nonoise, low_res_obj_stack, predicted_mat\n",
    "\n",
    "\n",
    "def average_gradients(tower_grads, take_average=True): # Take\n",
    "  \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "  Note that this function provides a synchronization point across all towers.\n",
    "  Args:\n",
    "    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n",
    "      is over individual gradients. The inner list is over the gradient\n",
    "      calculation for each tower.\n",
    "  Returns:\n",
    "     List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "     across all towers.\n",
    "  \"\"\"\n",
    "  average_grads = []\n",
    "  for grad_and_vars in zip(*tower_grads):\n",
    "    # Note that each grad_and_vars looks like the following:\n",
    "    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "    grads = []\n",
    "    for g, v in grad_and_vars:\n",
    "#      print('*'*100)\n",
    "#      print(g)\n",
    "#      print(v)\n",
    "      # Add 0 dimension to the gradients to represent the tower.\n",
    "      expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "      # Append on a 'tower' dimension which we will average over below.\n",
    "      grads.append(expanded_g)\n",
    "\n",
    "    # Average over the 'tower' dimension.\n",
    "    grad = tf.concat(axis=0, values=grads)\n",
    "    \n",
    "    if take_average:\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "    else:\n",
    "        grad = tf.reduce_sum(grad, 0)\n",
    "\n",
    "    # Keep in mind that the Variables are redundant because they are shared\n",
    "    # across towers. So .. we will just return the first tower's pointer to\n",
    "    # the Variable.\n",
    "    v = grad_and_vars[0][1]\n",
    "    grad_and_var = (grad, v)\n",
    "    average_grads.append(grad_and_var)\n",
    "  return average_grads\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_optical_parameters(training_data_folder,image_modality):\n",
    "    optical_parameters_dict = {}\n",
    "    if image_modality=='FP' or image_modality == 'FP_PP':\n",
    "        optical_parameters_dict['Ns_mat'] = np.load(training_data_folder + '/Ns_mat.npy')\n",
    "        optical_parameters_dict['scale_mat'] = np.load(training_data_folder + '/scale_mat.npy')\n",
    "        optical_parameters_dict['cen0'] = np.load(training_data_folder + '/cen0.npy')\n",
    "        optical_parameters_dict['P'] = np.load(training_data_folder + '/P.npy')\n",
    "        optical_parameters_dict['H0'] = np.load(training_data_folder + '/H0.npy')\n",
    "        optical_parameters_dict['Np'] = np.load(training_data_folder + '/Np.npy')\n",
    "        optical_parameters_dict['numLEDs'] = np.load(training_data_folder + '/numLEDs.npy')\n",
    "        optical_parameters_dict['N_obj'] = np.load(training_data_folder + '/N_obj.npy')\n",
    "        optical_parameters_dict['N_patch'] = np.load(training_data_folder + '/N_patch.npy')\n",
    "        optical_parameters_dict['num_patches'] = np.load(training_data_folder + '/num_patches.npy')\n",
    "        optical_parameters_dict['Nx_lowres'] = np.load(training_data_folder + '/Np.npy')\n",
    "        optical_parameters_dict['Nx_highres'] = np.load(training_data_folder + '/N_obj.npy')\n",
    "        optical_parameters_dict['NAfilter_synthetic'] = np.load(training_data_folder + '/NAfilter_synthetic.npy')\n",
    "        optical_parameters_dict['Nz'] = 1\n",
    "\n",
    "        num_elements = optical_parameters_dict['numLEDs']\n",
    "\n",
    "    elif image_modality=='STORM':\n",
    "        optical_parameters_dict['ZernikePolyMat'] = np.load(training_data_folder + '/ZernikePolyMat.npy')\n",
    "        optical_parameters_dict['H_NA'] = np.load(training_data_folder + '/H_NA.npy')\n",
    "        optical_parameters_dict['H_fresnel_stack'] = np.load(training_data_folder + '/H_fresnel_stack.npy')\n",
    "        optical_parameters_dict['Nx_lowres'] = np.load(training_data_folder + '/Nx.npy')\n",
    "        optical_parameters_dict['Nx_highres'] = np.load(training_data_folder + '/Nx.npy')\n",
    "        optical_parameters_dict['Nz'] = np.load(training_data_folder + '/Nz.npy')\n",
    "        optical_parameters_dict['num_wavelengths'] = np.load(training_data_folder + '/num_wavelengths.npy')\n",
    "        optical_parameters_dict['numCoeff'] = np.load(training_data_folder + '/numCoeff.npy')\n",
    "\n",
    "        num_elements = optical_parameters_dict['numCoeff']\n",
    "\n",
    "    elif image_modality=='HE':\n",
    "        only_noise = np.load(training_data_folder + '/only_noise.npy') # Option to keep magnification/resolution the same, but add noise\n",
    "        optical_parameters_dict['only_noise'] = only_noise\n",
    "\n",
    "        optical_parameters_dict['Nx_lowres'] = np.load(training_data_folder + '/Nx_lowres.npy')\n",
    "        optical_parameters_dict['Nx_highres'] = np.load(training_data_folder + '/Nx_highres.npy')\n",
    "        optical_parameters_dict['num_wavelengths'] = np.load(training_data_folder + '/num_wavelengths.npy')\n",
    "\n",
    "        if not(only_noise):\n",
    "            optical_parameters_dict['wavelength'] = np.load(training_data_folder + '/wavelength.npy')\n",
    "            optical_parameters_dict['h_blur'] = np.load(training_data_folder + '/h_blur.npy')\n",
    "            optical_parameters_dict['high_magn'] = np.load(training_data_folder + '/high_magn.npy')\n",
    "            optical_parameters_dict['low_magn'] = np.load(training_data_folder + '/low_magn.npy')\n",
    "            optical_parameters_dict['dpix_c'] = np.load(training_data_folder + '/dpix_c.npy')\n",
    "            optical_parameters_dict['low_NA'] = np.load(training_data_folder + '/low_NA.npy')\n",
    "\n",
    "        num_elements = None\n",
    "\n",
    "    elif image_modality=='phase':\n",
    "        optical_parameters_dict['ZernikePolyMat'] = np.load(training_data_folder + '/ZernikePolyMat.npy')\n",
    "        optical_parameters_dict['H_NA'] = np.load(training_data_folder + '/H_NA.npy')\n",
    "        optical_parameters_dict['H_fresnel'] = np.load(training_data_folder + '/H_fresnel.npy')\n",
    "        optical_parameters_dict['Nx_lowres'] = np.load(training_data_folder + '/Nx.npy')\n",
    "        optical_parameters_dict['Nx_highres'] = np.load(training_data_folder + '/Nx.npy')\n",
    "        optical_parameters_dict['numCoeff'] = np.load(training_data_folder + '/numCoeff.npy')\n",
    "        optical_parameters_dict['Nz'] = 1\n",
    "\n",
    "        num_elements = optical_parameters_dict['numCoeff']\n",
    "\n",
    "\n",
    "    return optical_parameters_dict, num_elements\n",
    "\n",
    "###### Functions for H&E\n",
    "\n",
    "def NAfilter(L,wavelength,NA,m):\n",
    "\n",
    "    #L is the side length of the observation and source fields (assume square fields), L is a float\n",
    "    #wavelength is the free space wavelength\n",
    "\n",
    "    dx=L/m\n",
    "    k=1./wavelength #wavenumber #2*pi/wavelength #1./wavelength\n",
    "\n",
    "    fx=tf.linspace(-1/(2*dx),1/(2*dx)-1/L,m) #freq coords\n",
    "\n",
    "    FX,FY=tf.meshgrid(fx,fx)\n",
    "\n",
    "    zeros = tf.cast(tf.zeros([m,m]),dtype=tf.complex64)\n",
    "    ones = tf.cast(tf.ones([m,m]),dtype=tf.complex64)\n",
    "\n",
    "    H = tf.where(tf.sqrt(FX**2+FY**2)<=NA*k,ones,zeros)\n",
    "\n",
    "\n",
    "#    H=fftshift(H,m,m)\n",
    "\n",
    "    return H\n",
    "\n",
    "def make_even(Np):\n",
    "\n",
    "    if np.ceil(Np)%2: # make Np even\n",
    "        Np = np.floor(Np)\n",
    "    else:\n",
    "        Np = np.ceil(Np)\n",
    "\n",
    "    Np = int(Np)\n",
    "\n",
    "    if Np % 2:\n",
    "        Np += 1\n",
    "\n",
    "    return Np\n",
    "\n",
    "def change_magn_img(img0, m, h_blur, high_magn, low_magn, dpix_c, wavelength, low_NA):\n",
    "\n",
    "    img = tf.cast(img0, dtype=tf.complex64)\n",
    "    img = img[0:m,0:m]\n",
    "\n",
    "    L = m*dpix_c/high_magn # [m]\n",
    "\n",
    "    cen = [m//2,m//2]\n",
    "    Np = m*low_magn/high_magn\n",
    "\n",
    "    Np = make_even(Np)\n",
    "\n",
    "    H_NA_R = NAfilter(L,wavelength[0],low_NA,m)\n",
    "    H_NA_G = NAfilter(L,wavelength[1],low_NA,m)\n",
    "    H_NA_B = NAfilter(L,wavelength[2],low_NA,m)\n",
    "\n",
    "\n",
    "    img_r = incoherent_filter_H(img[:,:,0], m, H_NA_R, cen, Np, h_blur)\n",
    "    img_g = incoherent_filter_H(img[:,:,1], m, H_NA_G, cen, Np, h_blur)\n",
    "    img_b = incoherent_filter_H(img[:,:,2], m, H_NA_B, cen, Np, h_blur)\n",
    "\n",
    "    img_r = tf.expand_dims(img_r, axis=2)\n",
    "    img_g = tf.expand_dims(img_g, axis=2)\n",
    "    img_b = tf.expand_dims(img_b, axis=2)\n",
    "    img=tf.concat([img_r,img_g,img_b],axis=2)\n",
    "\n",
    "#    img = tf.stack([img_r, img_g, img_b], axis=2)\n",
    "\n",
    "    return img0, img\n",
    "\n",
    "def incoherent_filter_H(u1, m, H, cen, Np, h_blur):\n",
    "\n",
    "#    H0 = H\n",
    "\n",
    "    H = F(Ft(H,m,m)*tf.conj(Ft(H,m,m)),m,m)\n",
    "    H=H/H[m//2,m//2]\n",
    "\n",
    "    U1 = F(u1,m,m)\n",
    "\n",
    "    U2=H*U1\n",
    "\n",
    "    #convolve with n x n filter with n = high_magn/low_magn\n",
    "    U2 = U2 * F(h_blur,m,m)\n",
    "\n",
    "    U2 = downsamp(U2,cen,Np)\n",
    "\n",
    "    u2=Ft(U2,Np,Np)/(m/Np)**2\n",
    "\n",
    "    u2 = tf.real(u2)\n",
    "\n",
    "    # Clip u2 at 0 and 255\n",
    "\n",
    "    zeros = tf.cast(tf.zeros([Np,Np]),dtype=tf.float32)\n",
    "    ones = 255*tf.cast(tf.ones([Np,Np]),dtype=tf.float32)\n",
    "\n",
    "    u2 = tf.where(u2>255,ones,u2)\n",
    "    u2 = tf.where(u2<0,zeros,u2)\n",
    "\n",
    "\n",
    "#    u2 = tf.cast(u2, dtype=tf.uint8)\n",
    "#    u2=Ft(U2,m,m)\n",
    "\n",
    "    return u2\n",
    "\n",
    "def filter_function_NA(u1,H_NA,Nx,incoherent=1):\n",
    "    #u1 is the source plane field\n",
    "    #Nx is u1.shape[0]\n",
    "    #dx is L/m\n",
    "\n",
    "    H = H_NA\n",
    "\n",
    "    if incoherent:\n",
    "        H=tf.fft2d(tf.ifft2d(H)*tf.conj(tf.ifft2d(H)))\n",
    "        #H=H/H[0,0]\n",
    "\n",
    "        U1=fftshift(u1,Nx,Nx)\n",
    "        U1=tf.fft2d(U1)\n",
    "\n",
    "        U2=H*U1\n",
    "        u2=fftshift(tf.ifft2d(U2),Nx,Nx)\n",
    "\n",
    "    else:\n",
    "        U1=fftshift(u1,Nx,Nx)\n",
    "        U1=tf.fft2d(U1)\n",
    "\n",
    "        U2=H*U1\n",
    "        u2=fftshift(tf.ifft2d(U2),Nx,Nx)\n",
    "        \n",
    "#        u2 = u2*np.conj(u2) # make into intensity object\n",
    "\n",
    "    return u2\n",
    "\n",
    "\n",
    "def read_img_file(img_path, channels):\n",
    "    img_file = tf.read_file(img_path)\n",
    "    img0 = tf.image.decode_image(img_file, channels=channels)\n",
    "    return img0\n",
    "\n",
    "def change_magn(img_path, m, h_blur, high_magn, low_magn, dpix_c, wavelength, low_NA, num_wavelengths):\n",
    "\n",
    "    img0 = read_img_file(img_path, num_wavelengths)\n",
    "\n",
    "    return change_magn_img(img0, m, h_blur, high_magn, low_magn, dpix_c, wavelength, low_NA)\n",
    "\n",
    "\n",
    "def change_magn_batch(img_stack, m, h_blur, high_magn, low_magn, dpix_c, wavelength, low_NA, batch_size):\n",
    "\n",
    "    for ii in range(batch_size):\n",
    "\n",
    "\n",
    "        ( _ , img) =change_magn_img(img_stack[ii,:,:,:], m, h_blur, high_magn, low_magn, dpix_c, wavelength, low_NA)\n",
    "\n",
    "        img = tf.expand_dims(img,axis=0)\n",
    "\n",
    "        if ii == 0:\n",
    "            img_stack_new = img\n",
    "        else:\n",
    "            img_stack_new = tf.concat([img_stack_new,img],0)\n",
    "\n",
    "#    img_stack_new = tf.cast(img_stack_new, dtype=tf.complex64)\n",
    "\n",
    "    return img_stack_new\n",
    "\n",
    "def add_poisson_noise(img0, img, noise_multiplier):\n",
    "\n",
    "    img = noise_multiplier*tf.cast(img, dtype=tf.float32)\n",
    "    img = tf.random_poisson(img, [1])\n",
    "    img = img/noise_multiplier\n",
    "\n",
    "    # Clip img at 0 and 255\n",
    "\n",
    "    zeros = tf.cast(tf.zeros_like(img),dtype=tf.float32)\n",
    "    ones = 255*tf.cast(tf.ones_like(img),dtype=tf.float32)\n",
    "\n",
    "    img = tf.where(img>255,ones,img)\n",
    "    img = tf.where(img<0,zeros,img)\n",
    "\n",
    "    img = tf.cast(img,dtype=tf.uint8)\n",
    "\n",
    "    img = tf.squeeze(img, axis=0)\n",
    "\n",
    "    return img0, img\n",
    "\n",
    "\n",
    "def upsample_rgb(low_res_obj_rgb, Np, N_obj, num_wavelengths):\n",
    "\n",
    "    for c in range(num_wavelengths):\n",
    "        upsampled_obj = upsample(low_res_obj_rgb[:,:,c], Np, N_obj)\n",
    "\n",
    "        upsampled_obj = tf.expand_dims(upsampled_obj, axis=2)\n",
    "\n",
    "        if c == 0:\n",
    "            upsampled_obj_stack = upsampled_obj\n",
    "        else:\n",
    "            upsampled_obj_stack = tf.concat([upsampled_obj_stack,upsampled_obj],2)\n",
    "\n",
    "    return upsampled_obj_stack\n",
    "\n",
    "\n",
    "def make_iterator_numpy(training_dataset, batch_size, num_GPUs, shuffle=False):\n",
    "    tr_data = tf.data.Dataset.from_tensor_slices(training_dataset)\n",
    "    tr_indices =tf.data.Dataset.from_tensor_slices(tf.constant(np.arange(0,training_dataset.shape[0],1),dtype = tf.int32))\n",
    "\n",
    "    tr_data = tf.data.Dataset.zip((tr_data, tr_indices))\n",
    "\n",
    "    tr_data = tr_data.repeat()\n",
    "\n",
    "    if shuffle:\n",
    "        tr_data = tr_data.shuffle(training_dataset.shape[0])\n",
    "\n",
    "    tr_data = tr_data.batch(batch_size*num_GPUs)\n",
    "    \n",
    "    return tr_data\n",
    "\n",
    "def make_iterator_FP_PP(training_dataset, lowres_training_dataset, \\\n",
    "                        batch_size, num_GPUs, shuffle=False):   \n",
    "\n",
    "    tr_data = tf.data.Dataset.from_tensor_slices(training_dataset)\n",
    "    tr_data_lowres = tf.data.Dataset.from_tensor_slices(lowres_training_dataset)\n",
    "    tr_indices =tf.data.Dataset.from_tensor_slices(tf.constant(np.arange(0,training_dataset.shape[0],1),dtype = tf.int32))\n",
    "\n",
    "    tr_data = tf.data.Dataset.zip((tr_data, tr_data_lowres, tr_indices))\n",
    "\n",
    "    tr_data = tr_data.repeat()\n",
    "\n",
    "    if shuffle:\n",
    "        tr_data = tr_data.shuffle(training_dataset.shape[0])\n",
    "\n",
    "    tr_data = tr_data.batch(batch_size*num_GPUs)\n",
    "    \n",
    "    return tr_data\n",
    "\n",
    "def make_complex_img(img_path, Nx, phase = True, intensity = False, library = tf):\n",
    "    if library == tf:\n",
    "        img0 = read_img_file(img_path, None)\n",
    "        img0 = library.reduce_sum(img0,axis=2)\n",
    "        img0 = img0[Nx/2:-Nx/2,Nx/2:-Nx/2]\n",
    "        img0 = library.cast(img0,dtype=library.complex64)\n",
    "    else:\n",
    "        files = glob.glob(img_path)\n",
    "        fileI = files[0]\n",
    "        img0 = misc.imread(fileI)\n",
    "        img0 = library.sum(img0, axis=2)\n",
    "        img0 = img0[0:Nx,0:Nx]\n",
    "        img0 = img0.astype(library.complex64)\n",
    "        \n",
    "    img0 = library.exp(1j*math.pi*1.0*(255.0*3-img0)/(255.0*3))\n",
    "    return img0\n",
    "\n",
    "def make_iterator_filename_FP(training_dataset, batch_size, num_GPUs, optical_parameters_dict, \\\n",
    "                              shuffle=False):\n",
    "    \n",
    "    Nx = optical_parameters_dict['Nx_highres']\n",
    "    H_NA = optical_parameters_dict['NAfilter_synthetic']\n",
    "    \n",
    "    training_dataset = tf.constant(training_dataset.tolist())\n",
    "    tr_data = tf.data.Dataset.from_tensor_slices(training_dataset)\n",
    "    tr_indices =tf.data.Dataset.from_tensor_slices(tf.constant(np.arange(0,int(training_dataset.shape[0]),1),dtype = tf.int32))\n",
    "\n",
    "    filter_function_NA_lambda = lambda u1: filter_function_NA(u1,H_NA,Nx,incoherent=0)\n",
    "    make_complex_img_lambda = lambda img_path: make_complex_img(img_path,Nx)\n",
    "\n",
    "    tr_data = tr_data.map(make_complex_img_lambda)\n",
    "    tr_data = tr_data.map(filter_function_NA_lambda)\n",
    "    tr_data = tf.data.Dataset.zip((tr_data, tr_indices))\n",
    "\n",
    "    tr_data = tr_data.repeat()\n",
    "\n",
    "    if shuffle:\n",
    "        tr_data = tr_data.shuffle(training_dataset.shape[0])\n",
    "\n",
    "    tr_data = tr_data.batch(batch_size*num_GPUs)\n",
    "    \n",
    "    return tr_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_STORM_stack(img_path, Nx):\n",
    "    img0 = read_img_file(img_path, None)\n",
    "    img0 = img0[0:Nx,0:Nx,:]\n",
    "    img0 = tf.expand_dims(img0, axis = 2)\n",
    "    img0 = tf.cast(img0, tf.float32)\n",
    "    return img0\n",
    "    \n",
    "    \n",
    "    \n",
    "def make_iterator_filename_STORM(training_dataset, batch_size, num_GPUs, optical_parameters_dict, \\\n",
    "                                 shuffle=False):\n",
    "    \n",
    "    Nx = optical_parameters_dict['Nx_highres']\n",
    "    \n",
    "    training_dataset = tf.constant(training_dataset.tolist())\n",
    "    tr_data = tf.data.Dataset.from_tensor_slices(training_dataset)\n",
    "    tr_indices =tf.data.Dataset.from_tensor_slices(tf.constant(np.arange(0,int(training_dataset.shape[0]),1),dtype = tf.int32))\n",
    "\n",
    "\n",
    "    create_STORM_stack_lambda = lambda img_path: create_STORM_stack(img_path, Nx)\n",
    "    \n",
    "    tr_data = tr_data.map(create_STORM_stack_lambda)\n",
    "    tr_data = tf.data.Dataset.zip((tr_data, tr_indices))\n",
    "\n",
    "    tr_data = tr_data.repeat()\n",
    "\n",
    "    if shuffle:\n",
    "        tr_data = tr_data.shuffle(training_dataset.shape[0])\n",
    "\n",
    "    tr_data = tr_data.batch(batch_size*num_GPUs)\n",
    "    \n",
    "    return tr_data\n",
    "\n",
    "def make_iterator_filename(training_dataset, add_noise, poisson_noise_multiplier, batch_size, \\\n",
    "                           num_GPUs, optical_parameters_dict, shuffle = False):\n",
    "\n",
    "    only_noise = optical_parameters_dict['only_noise']\n",
    "    num_wavelengths = optical_parameters_dict['num_wavelengths']\n",
    "\n",
    "    training_dataset = tf.constant(training_dataset.tolist())\n",
    "    tr_data = tf.data.Dataset.from_tensor_slices(training_dataset)\n",
    "    tr_indices =tf.data.Dataset.from_tensor_slices(tf.constant(np.arange(0,int(training_dataset.shape[0]),1),dtype = tf.int32))\n",
    "\n",
    "\n",
    "\n",
    "    if only_noise:\n",
    "        read_img_file_lambda = lambda img_path: read_img_file(img_path, num_wavelengths)\n",
    "        tr_data = tr_data.map(lambda img_path: (read_img_file_lambda(img_path),read_img_file_lambda(img_path)))\n",
    "    else:\n",
    "        change_magn_lambda = lambda img_path: change_magn(img_path,\n",
    "                                                  optical_parameters_dict['Nx_highres'],\n",
    "                                                  optical_parameters_dict['h_blur'],\n",
    "                                                  optical_parameters_dict['high_magn'],\n",
    "                                                  optical_parameters_dict['low_magn'],\n",
    "                                                  optical_parameters_dict['dpix_c'],\n",
    "                                                  optical_parameters_dict['wavelength'],\n",
    "                                                  optical_parameters_dict['low_NA'],\n",
    "                                                  num_wavelengths)\n",
    "        tr_data = tr_data.map(change_magn_lambda)\n",
    "\n",
    "    add_poisson_noise_lambda = lambda img0, img: add_poisson_noise(img0, img, poisson_noise_multiplier)\n",
    "\n",
    "    if only_noise and not(add_noise):\n",
    "        print('Warning: only_noise = True and add_noise = False!!')\n",
    "\n",
    "    if add_noise:\n",
    "        tr_data = tr_data.map(add_poisson_noise_lambda)\n",
    "\n",
    "    tr_data = tf.data.Dataset.zip((tr_data, tr_indices))\n",
    "\n",
    "    tr_data = tr_data.repeat()\n",
    "    \n",
    "    if shuffle:\n",
    "        tr_data = tr_data.shuffle(int(training_dataset.shape[0]))    \n",
    "    \n",
    "    tr_data = tr_data.batch(batch_size*num_GPUs)\n",
    "\n",
    "    return tr_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tower_loss_HE(low_res_obj_batch, \\\n",
    "                  high_res_obj_batch, training, \\\n",
    "                  use_batch_norm, variance_reg, sqrt_reg, \\\n",
    "                  dropout_prob, layers_dropout, batch_size, max_internal_iter, merit_stopping_point, \\\n",
    "                  optical_parameters_dict, autoencode_init_type, init_type_bias, init_type_resid, \\\n",
    "                  kernel_multiplier, num_layers_autoencode, skip_interval, num_blocks):\n",
    "    \n",
    "    only_noise = optical_parameters_dict['only_noise']\n",
    "    Nx_lowres = optical_parameters_dict['Nx_lowres']\n",
    "    Nx_highres = optical_parameters_dict['Nx_highres']\n",
    "    num_wavelengths = optical_parameters_dict['num_wavelengths']\n",
    "\n",
    "    if not(only_noise):\n",
    "        wavelength = optical_parameters_dict['wavelength']\n",
    "        h_blur = optical_parameters_dict['h_blur']\n",
    "        high_magn = optical_parameters_dict['high_magn']\n",
    "        low_magn = optical_parameters_dict['low_magn']\n",
    "        dpix_c = optical_parameters_dict['dpix_c']\n",
    "        low_NA = optical_parameters_dict['low_NA']\n",
    "\n",
    "\n",
    "    with tf.variable_scope(\"optical_transform\"):\n",
    "\n",
    "        if only_noise:\n",
    "            upsampled_obj_stack = low_res_obj_batch\n",
    "        else:\n",
    "            # upsample the low_res_obj_stack\n",
    "            simple_upsample = 0\n",
    "            if simple_upsample:\n",
    "                low_res_obj_batch = tf.cast(low_res_obj_batch, tf.complex64)\n",
    "                for ii in range(batch_size):\n",
    "                    upsampled_obj = upsample_rgb(low_res_obj_batch[ii,:,:,:], Nx_lowres, Nx_highres, num_wavelengths)\n",
    "\n",
    "                    upsampled_obj = tf.expand_dims(upsampled_obj,axis=0)\n",
    "                    if ii == 0:\n",
    "                        upsampled_obj_stack = upsampled_obj\n",
    "                    else:\n",
    "                        upsampled_obj_stack = tf.concat([upsampled_obj_stack,upsampled_obj],0)\n",
    "            else:\n",
    "                upsampled_obj_stack = tf.image.resize_images(low_res_obj_batch, [int(Nx_highres), int(Nx_highres)], \\\n",
    "                                                       method=tf.image.ResizeMethod.BICUBIC, align_corners=False)\n",
    "\n",
    "        upsampled_obj_stack = tf.cast(upsampled_obj_stack, tf.float32)\n",
    "\n",
    "    with tf.variable_scope(\"neural_net\"):\n",
    "\n",
    "        num_nets = num_wavelengths\n",
    "        input_layer_list = []\n",
    "\n",
    "        for w in range(num_wavelengths):\n",
    "\n",
    "            input_layer = tf.expand_dims(upsampled_obj_stack[:,:,:,w], axis=3)\n",
    "            input_layer_list.append(input_layer)\n",
    "\n",
    "#        len(input_layer) should equal num_nets\n",
    "\n",
    "#        input_layer_r = tf.expand_dims(upsampled_obj_stack[:,:,:,0], axis=3)\n",
    "#        input_layer_g = tf.expand_dims(upsampled_obj_stack[:,:,:,1], axis=3)\n",
    "#        input_layer_b = tf.expand_dims(upsampled_obj_stack[:,:,:,2], axis=3)\n",
    "#\n",
    "#\n",
    "#        input_layer_list = [input_layer_r, input_layer_g, input_layer_b]\n",
    "\n",
    "        predicted_mat = find_predicted_mat('HE', num_nets, input_layer_list, Nx_highres, batch_size, layers_dropout, dropout_prob, \n",
    "                       use_batch_norm, autoencode_init_type, init_type_bias, init_type_resid, kernel_multiplier, variance_reg, training, \\\n",
    "                       num_layers_autoencode, skip_interval, num_blocks, optical_parameters_dict)\n",
    "        \n",
    "    with tf.variable_scope(\"neural_net\"): \n",
    "            \n",
    "\n",
    "#        ### convert predicted_mat down to low_res_obj_predicted\n",
    "        if only_noise:\n",
    "            low_res_obj_batch_predicted = low_res_obj_batch\n",
    "\n",
    "        else:\n",
    "            low_res_obj_batch_predicted = change_magn_batch(predicted_mat, Nx_highres, h_blur, \\\n",
    "                                                            high_magn, low_magn, dpix_c, wavelength, low_NA, batch_size)\n",
    "\n",
    "            low_res_obj_batch_predicted = tf.cast(low_res_obj_batch_predicted, tf.float32)\n",
    "            low_res_obj_batch = tf.cast(low_res_obj_batch, tf.float32)\n",
    "            loss_low_res = tf.reduce_sum(tf.square(low_res_obj_batch - low_res_obj_batch_predicted))\n",
    "\n",
    "\n",
    "###################\n",
    "        step_size = variable_on_cpu('step_size', 1e-7, tf.float32, trainable = False) # XXX make step_size trainable\n",
    "\n",
    "    with tf.variable_scope(\"iteration_variable\"):\n",
    "        i = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "\n",
    "    with tf.variable_scope(\"neural_net\"):\n",
    "\n",
    "        if not(only_noise):\n",
    "            if max_internal_iter > 0:\n",
    "                predicted_mat, loss_low_res = iterative_solver_HE(predicted_mat, Nx_highres, h_blur, \\\n",
    "                               high_magn, low_magn, dpix_c, wavelength, \\\n",
    "                               low_NA, low_res_obj_batch, step_size, max_internal_iter, \\\n",
    "                               merit_stopping_point, loss_low_res, i, \\\n",
    "                               batch_size)\n",
    "\n",
    "        high_res_obj_batch = tf.cast(high_res_obj_batch, tf.float32)\n",
    "\n",
    "        loss = tf.reduce_sum(tf.square(high_res_obj_batch - predicted_mat))\n",
    "\n",
    "        if only_noise:\n",
    "            loss_low_res = loss\n",
    "        \n",
    "        loss_grad = grad_diff_loss(predicted_mat, high_res_obj_batch)\n",
    "\n",
    "    return loss, loss_grad, loss_low_res, low_res_obj_batch_predicted, low_res_obj_batch, predicted_mat\n",
    "    #output names are: loss, loss_grad, optical_element, low_res_obj_stack_nonoise, low_res_obj_stack, predicted_mat\n",
    "    #for only_noise = True, loss_low_res is set to loss, and low_res_obj_batch_predicted is set to low_res_obj_batch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
