{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-d DATASET_FOLDER] [--count TOTAL_PATCHES]\n",
      "                             [--overlap OVERLAP] [--uf UPSAMPLE_FACTOR]\n",
      "                             [--ps PATCH_SIZE] [--nx0 NSTART_X_0]\n",
      "                             [--ny0 NSTART_Y_0] [--ns NUM_STACKS]\n",
      "                             [--sp SAVE_PATCHES] [--zi Z_IND]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /mnt/saturn/jupyterhub_data/fveronf1/.local/share/jupyter/runtime/kernel-7e8e0703-a59d-45a0-826d-44e6abeb4895.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "from FP_Reconstruction_Functions_3D import read_images, read_images_single_stack\n",
    "import os, sys\n",
    "from VisualizerMultiPatchFunctions import load_final_var, CreateFig, save_pngs_patch\n",
    "import glob\n",
    "    \n",
    "### Command Line Inputs\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Get command line args')\n",
    "\n",
    "parser.add_argument('-d', type=str, action='store', dest='dataset_folder', \\\n",
    "                        help='main folder containing the subfolders')\n",
    "\n",
    "parser.add_argument('--count', type=int, action='store', dest='total_patches', \\\n",
    "                    help='Number of total patches', \\\n",
    "                    default = 16)    \n",
    "\n",
    "parser.add_argument('--overlap', type=int, action='store', dest='overlap', \\\n",
    "                    help='overlap of the patches', \\\n",
    "                    default = 64) \n",
    "\n",
    "parser.add_argument('--uf', type=int, action='store', dest='upsample_factor', \\\n",
    "                    help='N_obj/Np, the upsample factor to go from low res to high res', \\\n",
    "                    default = 2) \n",
    "\n",
    "parser.add_argument('--ps', type=int, action='store', dest='patch_size', \\\n",
    "                    help='Np, the size of a patch', \\\n",
    "                    default = 512) \n",
    "\n",
    "parser.add_argument('--nx0', type=int, action='store', dest='nstart_x_0', \\\n",
    "                    help='Initial starting coordinate for defining region of interest, row coordinate', \\\n",
    "                    default = 0)\n",
    "\n",
    "parser.add_argument('--ny0', type=int, action='store', dest='nstart_y_0', \\\n",
    "                    help='Initial starting coordinate for defining region of interest, column coordinate', \\\n",
    "                    default = 0)   \n",
    "\n",
    "parser.add_argument('--ns', type=int, action='store', dest='num_stacks', \\\n",
    "                    help='num_stacks', \\\n",
    "                    default = 1)       \n",
    "\n",
    "parser.add_argument('--sp', type=int, action='store', dest='save_patches', \\\n",
    "                    help='save_patches', \\\n",
    "                    default = 4)    \n",
    "\n",
    "\n",
    "parser.add_argument('--zi', type=int, action='store', dest='z_ind', \\\n",
    "                    help='z_ind', \\\n",
    "                    default = 2)  \n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "### Inputs from command line args\n",
    "training_data_folder = args.dataset_folder \n",
    "total_patches = args.total_patches\n",
    "overlap = args.overlap\n",
    "upsample_factor = args.upsample_factor\n",
    "patch_size = args.patch_size\n",
    "nstart_x_0 = args.nstart_x_0\n",
    "nstart_y_0 = args.nstart_y_0\n",
    "num_stacks = args.num_stacks\n",
    "save_patches = args.save_patches\n",
    "z_ind = args.z_ind\n",
    "\n",
    "### read in final object data from each patch\n",
    "all_high_res_guess_1 = []\n",
    "for i in range(total_patches):\n",
    "    output_folder = 'patch_' + str(i)\n",
    "    folder_name = training_data_folder + '/' + output_folder\n",
    "    iter_vec = np.load(folder_name + '/iter_vec.npy')\n",
    "    high_res_guess_1 = load_final_var('high_res_guess',folder_name, iter_vec)\n",
    "    all_high_res_guess_1.append(high_res_guess_1[z_ind,:,:])\n",
    "\n",
    "\n",
    "### merge together all columns for each row    \n",
    "x_strips = []\n",
    "x_patches_vec = np.arange(np.sqrt(total_patches))\n",
    "\n",
    "count = 0\n",
    "\n",
    "indices = np.expand_dims(np.arange(0,overlap*upsample_factor)/float(overlap*upsample_factor),axis=0)\n",
    "\n",
    "for x in x_patches_vec:\n",
    "    x_strip_i = np.zeros([patch_size*upsample_factor,(patch_size-overlap)*len(x_patches_vec)*upsample_factor \\\n",
    "                          + overlap*upsample_factor], dtype=np.complex64)\n",
    "    for y_i, y in enumerate(x_patches_vec):\n",
    "        patch_i = all_high_res_guess_1[count]\n",
    "        if y_i == 0: #first patch\n",
    "            patch_i[:,-overlap*upsample_factor:] = patch_i[:,-overlap*upsample_factor:]*(1-indices)\n",
    "            x_strip_i[:,0:patch_size*upsample_factor] = patch_i\n",
    "        elif y_i == (len(x_patches_vec) - 1): #last patch\n",
    "            patch_i[:,0:overlap*upsample_factor] = patch_i[:,0:overlap*upsample_factor]*indices\n",
    "            x_strip_i[:,y_i*(patch_size-overlap)*upsample_factor:] = \\\n",
    "                x_strip_i[:,y_i*(patch_size-overlap)*upsample_factor:] + patch_i\n",
    "        else: #middle patch\n",
    "            patch_i[:,0:overlap*upsample_factor] = patch_i[:,0:overlap*upsample_factor]*indices\n",
    "            patch_i[:,-overlap*upsample_factor:] = patch_i[:,-overlap*upsample_factor:]*(1-indices)\n",
    "            \n",
    "            x_strip_i[:,y_i*(patch_size-overlap)*upsample_factor:\\\n",
    "                      y_i*(patch_size-overlap)*upsample_factor+patch_size*upsample_factor] = \\\n",
    "                      x_strip_i[:,y_i*(patch_size-overlap)*upsample_factor:\\\n",
    "                      y_i*(patch_size-overlap)*upsample_factor+patch_size*upsample_factor] + \\\n",
    "                      patch_i\n",
    "        count += 1\n",
    "    x_strips.append(x_strip_i)\n",
    "\n",
    "\n",
    "### merge together all rows\n",
    "total_N_obj = (patch_size-overlap)*upsample_factor*len(x_patches_vec)+overlap*upsample_factor     \n",
    "final_obj =  np.zeros([total_N_obj, total_N_obj],dtype=np.complex64)  \n",
    "for y_i,y in enumerate(x_patches_vec):\n",
    "    strip_i = x_strips[y_i]\n",
    "    if y_i == 0: #first strip\n",
    "        strip_i[-overlap*upsample_factor:,:] = strip_i[-overlap*upsample_factor:,:]*np.transpose((1-indices))\n",
    "        final_obj[0:patch_size*upsample_factor,:] = strip_i\n",
    "    elif y_i == (len(x_patches_vec) - 1): #last strip\n",
    "        strip_i[0:overlap*upsample_factor,:] = strip_i[0:overlap*upsample_factor,:]*np.transpose(indices)\n",
    "        final_obj[y_i*(patch_size-overlap)*upsample_factor:,:] = \\\n",
    "                final_obj[y_i*(patch_size-overlap)*upsample_factor:,:] + strip_i\n",
    "    else: #middle strip\n",
    "        strip_i[0:overlap*upsample_factor,:] = strip_i[0:overlap*upsample_factor,:]*np.transpose(indices)\n",
    "        strip_i[-overlap*upsample_factor:,:] = strip_i[-overlap*upsample_factor:,:]*np.transpose((1-indices)) \n",
    "        final_obj[y_i*(patch_size-overlap)*upsample_factor:\\\n",
    "                      y_i*(patch_size-overlap)*upsample_factor+patch_size*upsample_factor,:] = \\\n",
    "                      final_obj[y_i*(patch_size-overlap)*upsample_factor:\\\n",
    "                      y_i*(patch_size-overlap)*upsample_factor+patch_size*upsample_factor,:] + \\\n",
    "                      strip_i\n",
    "\n",
    "  \n",
    "### Get low res images\n",
    "\n",
    "low_res_stack_actual_ave = read_images(training_data_folder, total_N_obj/upsample_factor, [nstart_x_0,nstart_y_0], False, 0, num_stacks)\n",
    "\n",
    "low_res_stack_actual = np.zeros([num_stacks, low_res_stack_actual_ave.shape[0], low_res_stack_actual_ave.shape[1], \\\n",
    "                                 low_res_stack_actual_ave.shape[2]], dtype=np.uint16)\n",
    "for stack_i in range(1,num_stacks+1):\n",
    "    low_res_stack_actual[stack_i-1,:,:,:] = read_images_single_stack(training_data_folder, total_N_obj/upsample_factor, [nstart_x_0,nstart_y_0], False, 0, stack_i)\n",
    "\n",
    "### If folder contains \"LEDPattern\" then save those as well\n",
    "num_LEDPattern_imgs = len(glob.glob(training_data_folder + \"/LEDPattern/Photo000*.png\"))\n",
    "\n",
    "if num_LEDPattern_imgs>0:\n",
    "    LEDPattern_stack = read_images_single_stack(training_data_folder, total_N_obj/upsample_factor, [nstart_x_0,nstart_y_0], False, 0, 0, LEDPattern = True)\n",
    "    LEDPattern = True\n",
    "else:\n",
    "    LEDPattern = False\n",
    "    LEDPattern_stack = None\n",
    "\n",
    "\n",
    "### Make figures\n",
    "\n",
    "CreateFig(np.sum(low_res_stack_actual_ave, axis=0),'low_res_stack_actual_sum',training_data_folder,title='low_res_stack_actual sum', vmin=50000, vmax=350000)\n",
    "CreateFig(low_res_stack_actual_ave[34,:,:],'low_res_stack_actual_img0',training_data_folder,title='low_res_stack_actual img0')\n",
    "\n",
    "#CreateFig(np.sum(low_res_stack_actual[0,:,:,:], axis=0),'low_res_stack_single_stack',training_data_folder,title='low_res_stack_single_stack', vmin=50000, vmax=350000)\n",
    "\n",
    "CreateFig(np.abs(final_obj),\\\n",
    "          'final_obj_abs',training_data_folder,title='final_obj_abs')\n",
    "CreateFig(np.angle(final_obj),\\\n",
    "          'final_obj_angle',training_data_folder,title='final_obj_angle')\n",
    "\n",
    "### Save Data\n",
    "\n",
    "numLEDs = low_res_stack_actual.shape[1]\n",
    "\n",
    "#np.save(training_data_folder + '/low_res_stack_actual_ave.npy', low_res_stack_actual_ave)\n",
    "np.save(training_data_folder + '/low_res_stack_actual.npy', low_res_stack_actual)\n",
    "np.save(training_data_folder + '/final_obj.npy', final_obj)\n",
    "\n",
    "\n",
    "#np.save(training_data_folder + '/Np.npy', total_N_obj/upsample_factor)\n",
    "#np.save(training_data_folder + '/N_obj.npy', total_N_obj)\n",
    "#np.save(training_data_folder + '/numLEDs.npy', numLEDs)\n",
    "\n",
    "\n",
    "# Output low-resolution image\n",
    "low_res_stack_actual_ave = np.round(low_res_stack_actual_ave)\n",
    "low_res_stack_actual_ave[low_res_stack_actual_ave > (2**16 - 1)] = 2**16 - 1\n",
    "low_res_stack_actual_ave[low_res_stack_actual_ave < 0] = 0\n",
    "low_res_stack_actual_ave = low_res_stack_actual_ave.astype(np.uint16)\n",
    "\n",
    "\n",
    "if 0:\n",
    "    lowres_training_dataset = np.expand_dims(np.transpose(low_res_stack_actual_ave, axes=[1,2,0]),axis=0)\n",
    "    training_dataset = np.expand_dims(final_obj,axis=0)\n",
    "    \n",
    "    lowres_training_dataset = lowres_training_dataset[:,0:464*2,0:464*2,:]\n",
    "    training_dataset = training_dataset[:,0:928*2,0:928*2]\n",
    "    \n",
    "    np.save(training_data_folder + '/lowres_training_dataset.npy', \\\n",
    "            lowres_training_dataset)\n",
    "    np.save(training_data_folder + '/training_dataset.npy', training_dataset)\n",
    "    \n",
    "    np.save(training_data_folder + '/Np.npy', 464*2)\n",
    "    np.save(training_data_folder + '/N_obj.npy', 928*2)\n",
    "    np.save(training_data_folder + '/numLEDs.npy', numLEDs)\n",
    "\n",
    "\n",
    "\n",
    "N_obj_save = total_N_obj/save_patches\n",
    "Np_save = total_N_obj/upsample_factor/save_patches\n",
    "np.save(training_data_folder +  '/Np.npy', Np_save)\n",
    "np.save(training_data_folder +  '/N_obj.npy', N_obj_save)\n",
    "np.save(training_data_folder +  '/numLEDs.npy', numLEDs)\n",
    "\n",
    "lower_bnd = -50\n",
    "upper_bnd = 50\n",
    "bnds =np.array([np.max(np.real(final_obj)), np.min(np.real(final_obj)), np.max(np.imag(final_obj)),np.min(np.imag(final_obj))])\n",
    "\n",
    "if np.min(bnds) < lower_bnd:\n",
    "    print('Warning, truncating final_obj, lower bound.')\n",
    "if np.max(bnds) > upper_bnd:\n",
    "    print('Warning, truncating final_obj, upper bound.')\n",
    "\n",
    "\n",
    "patch_num = 0\n",
    "for p_x in range(save_patches):\n",
    "    for p_y in range(save_patches):\n",
    "        save_pngs_patch(p_x, p_y, patch_num, Np_save, N_obj_save, numLEDs, \\\n",
    "                    training_data_folder, low_res_stack_actual_ave, final_obj, \\\n",
    "                    lower_bnd, upper_bnd, LEDPattern, LEDPattern_stack)\n",
    "        patch_num += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### reconstruct complex obj from pngs\n",
    "#real_part = imageio.imread(highres_real_filename)\n",
    "#imag_part = imageio.imread(highres_imag_filename)\n",
    "#\n",
    "#real_part = unprocess_final_obj(real_part)\n",
    "#imag_part = unprocess_final_obj(imag_part)\n",
    "#\n",
    "#img = real_part + 1j*imag_part\n",
    "#plt.figure()\n",
    "#plt.imshow(np.abs(img))\n",
    "#\n",
    "#plt.figure()\n",
    "#plt.imshow(np.angle(img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
